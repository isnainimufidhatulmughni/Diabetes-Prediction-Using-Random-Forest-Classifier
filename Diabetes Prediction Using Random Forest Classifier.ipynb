{"cells":[{"cell_type":"markdown","id":"f69a8f2b-af9c-49a2-b29a-ec5d8808b228","metadata":{},"source":["# **Classification with Random Forest Classifier in Python**\n"]},{"cell_type":"markdown","id":"374ba9e4-aba3-4ddb-a93a-fb23a6536440","metadata":{},"source":["### Installing required libraries\n"]},{"cell_type":"code","execution_count":1,"id":"d07a0358-56b9-4736-b164-7729b9d3c934","metadata":{},"outputs":[],"source":["%%capture\n","#pip install numpy==1.26.4 pandas==2.2.2 matplotlib==3.8.4 seaborn==0.13.2 scikit-learn==1.5.0 xlrd==2.0.1 openpyxl==3.1.4"]},{"cell_type":"markdown","id":"d8fbb9fd-b5ba-4eea-b216-520613b0fcd1","metadata":{},"source":["### Importing required libraries\n"]},{"cell_type":"code","execution_count":37,"id":"f108e65c-b517-4bb4-a2bd-f7c4769ff9f0","metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","from itertools import accumulate\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import scale, LabelEncoder\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n","from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n","from sklearn.feature_selection import f_classif\n","from sklearn.utils import resample\n","\n","sns.set_context('notebook')\n","sns.set_style('white')"]},{"cell_type":"markdown","id":"a40865ca-8fb5-426e-8321-e1589be8b811","metadata":{},"source":["## Load the data\n","\n","The data set that i'll use is about classifying patients into diabetes positive or negative given their medical information such as their cholesterol, glucose levels, age, gender, height, waist, and hip measurements. This data set was taken from: [data.world](https://data.world/search?q=diabetes+classification).\n"]},{"cell_type":"code","execution_count":3,"id":"0ac52dff-77b6-4699-9cef-c425288a6e85","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 390 entries, 0 to 389\n","Data columns (total 18 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   Patient number   390 non-null    int64  \n"," 1   Cholesterol      390 non-null    int64  \n"," 2   Glucose          390 non-null    int64  \n"," 3   HDL Chol         390 non-null    int64  \n"," 4   Chol/HDL ratio   390 non-null    float64\n"," 5   Age              390 non-null    int64  \n"," 6   Gender           390 non-null    object \n"," 7   Height           390 non-null    int64  \n"," 8   Weight           390 non-null    int64  \n"," 9   BMI              390 non-null    float64\n"," 10  Systolic BP      390 non-null    int64  \n"," 11  Diastolic BP     390 non-null    int64  \n"," 12  waist            390 non-null    int64  \n"," 13  hip              390 non-null    int64  \n"," 14  Waist/hip ratio  390 non-null    float64\n"," 15  Diabetes         390 non-null    object \n"," 16  Unnamed: 16      1 non-null      float64\n"," 17  Unnamed: 17      1 non-null      float64\n","dtypes: float64(5), int64(11), object(2)\n","memory usage: 55.0+ KB\n"]}],"source":["# Read the dataset\n","df = pd.read_excel('Diabetes_Classification (1).xlsx')\n","df.info()"]},{"cell_type":"code","execution_count":4,"id":"fb86ee73-82e1-4581-97ef-ad60579b6415","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Patient number</th>\n","      <th>Cholesterol</th>\n","      <th>Glucose</th>\n","      <th>HDL Chol</th>\n","      <th>Chol/HDL ratio</th>\n","      <th>Age</th>\n","      <th>Gender</th>\n","      <th>Height</th>\n","      <th>Weight</th>\n","      <th>BMI</th>\n","      <th>Systolic BP</th>\n","      <th>Diastolic BP</th>\n","      <th>waist</th>\n","      <th>hip</th>\n","      <th>Waist/hip ratio</th>\n","      <th>Diabetes</th>\n","      <th>Unnamed: 16</th>\n","      <th>Unnamed: 17</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>193</td>\n","      <td>77</td>\n","      <td>49</td>\n","      <td>3.9</td>\n","      <td>19</td>\n","      <td>female</td>\n","      <td>61</td>\n","      <td>119</td>\n","      <td>22.5</td>\n","      <td>118</td>\n","      <td>70</td>\n","      <td>32</td>\n","      <td>38</td>\n","      <td>0.84</td>\n","      <td>No diabetes</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>146</td>\n","      <td>79</td>\n","      <td>41</td>\n","      <td>3.6</td>\n","      <td>19</td>\n","      <td>female</td>\n","      <td>60</td>\n","      <td>135</td>\n","      <td>26.4</td>\n","      <td>108</td>\n","      <td>58</td>\n","      <td>33</td>\n","      <td>40</td>\n","      <td>0.83</td>\n","      <td>No diabetes</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>217</td>\n","      <td>75</td>\n","      <td>54</td>\n","      <td>4.0</td>\n","      <td>20</td>\n","      <td>female</td>\n","      <td>67</td>\n","      <td>187</td>\n","      <td>29.3</td>\n","      <td>110</td>\n","      <td>72</td>\n","      <td>40</td>\n","      <td>45</td>\n","      <td>0.89</td>\n","      <td>No diabetes</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>226</td>\n","      <td>97</td>\n","      <td>70</td>\n","      <td>3.2</td>\n","      <td>20</td>\n","      <td>female</td>\n","      <td>64</td>\n","      <td>114</td>\n","      <td>19.6</td>\n","      <td>122</td>\n","      <td>64</td>\n","      <td>31</td>\n","      <td>39</td>\n","      <td>0.79</td>\n","      <td>No diabetes</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>164</td>\n","      <td>91</td>\n","      <td>67</td>\n","      <td>2.4</td>\n","      <td>20</td>\n","      <td>female</td>\n","      <td>70</td>\n","      <td>141</td>\n","      <td>20.2</td>\n","      <td>122</td>\n","      <td>86</td>\n","      <td>32</td>\n","      <td>39</td>\n","      <td>0.82</td>\n","      <td>No diabetes</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Patient number  Cholesterol  Glucose  HDL Chol  Chol/HDL ratio  Age  \\\n","0               1          193       77        49             3.9   19   \n","1               2          146       79        41             3.6   19   \n","2               3          217       75        54             4.0   20   \n","3               4          226       97        70             3.2   20   \n","4               5          164       91        67             2.4   20   \n","\n","   Gender  Height  Weight   BMI  Systolic BP  Diastolic BP  waist  hip  \\\n","0  female      61     119  22.5          118            70     32   38   \n","1  female      60     135  26.4          108            58     33   40   \n","2  female      67     187  29.3          110            72     40   45   \n","3  female      64     114  19.6          122            64     31   39   \n","4  female      70     141  20.2          122            86     32   39   \n","\n","   Waist/hip ratio     Diabetes  Unnamed: 16  Unnamed: 17  \n","0             0.84  No diabetes          6.0          6.0  \n","1             0.83  No diabetes          NaN          NaN  \n","2             0.89  No diabetes          NaN          NaN  \n","3             0.79  No diabetes          NaN          NaN  \n","4             0.82  No diabetes          NaN          NaN  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","id":"ce1d1cbe-9614-4075-b82d-7a3922390eb9","metadata":{},"source":["The last two columns are not relevant. You can remove them.\n"]},{"cell_type":"code","execution_count":5,"id":"3a4f5ac4-47e9-4044-a91d-849575a92fd9","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Patient number</th>\n","      <th>Cholesterol</th>\n","      <th>Glucose</th>\n","      <th>HDL Chol</th>\n","      <th>Chol/HDL ratio</th>\n","      <th>Age</th>\n","      <th>Gender</th>\n","      <th>Height</th>\n","      <th>Weight</th>\n","      <th>BMI</th>\n","      <th>Systolic BP</th>\n","      <th>Diastolic BP</th>\n","      <th>waist</th>\n","      <th>hip</th>\n","      <th>Waist/hip ratio</th>\n","      <th>Diabetes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>193</td>\n","      <td>77</td>\n","      <td>49</td>\n","      <td>3.9</td>\n","      <td>19</td>\n","      <td>female</td>\n","      <td>61</td>\n","      <td>119</td>\n","      <td>22.5</td>\n","      <td>118</td>\n","      <td>70</td>\n","      <td>32</td>\n","      <td>38</td>\n","      <td>0.84</td>\n","      <td>No diabetes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>146</td>\n","      <td>79</td>\n","      <td>41</td>\n","      <td>3.6</td>\n","      <td>19</td>\n","      <td>female</td>\n","      <td>60</td>\n","      <td>135</td>\n","      <td>26.4</td>\n","      <td>108</td>\n","      <td>58</td>\n","      <td>33</td>\n","      <td>40</td>\n","      <td>0.83</td>\n","      <td>No diabetes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>217</td>\n","      <td>75</td>\n","      <td>54</td>\n","      <td>4.0</td>\n","      <td>20</td>\n","      <td>female</td>\n","      <td>67</td>\n","      <td>187</td>\n","      <td>29.3</td>\n","      <td>110</td>\n","      <td>72</td>\n","      <td>40</td>\n","      <td>45</td>\n","      <td>0.89</td>\n","      <td>No diabetes</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>226</td>\n","      <td>97</td>\n","      <td>70</td>\n","      <td>3.2</td>\n","      <td>20</td>\n","      <td>female</td>\n","      <td>64</td>\n","      <td>114</td>\n","      <td>19.6</td>\n","      <td>122</td>\n","      <td>64</td>\n","      <td>31</td>\n","      <td>39</td>\n","      <td>0.79</td>\n","      <td>No diabetes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>164</td>\n","      <td>91</td>\n","      <td>67</td>\n","      <td>2.4</td>\n","      <td>20</td>\n","      <td>female</td>\n","      <td>70</td>\n","      <td>141</td>\n","      <td>20.2</td>\n","      <td>122</td>\n","      <td>86</td>\n","      <td>32</td>\n","      <td>39</td>\n","      <td>0.82</td>\n","      <td>No diabetes</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>385</th>\n","      <td>386</td>\n","      <td>227</td>\n","      <td>105</td>\n","      <td>44</td>\n","      <td>5.2</td>\n","      <td>83</td>\n","      <td>female</td>\n","      <td>59</td>\n","      <td>125</td>\n","      <td>25.2</td>\n","      <td>150</td>\n","      <td>90</td>\n","      <td>35</td>\n","      <td>40</td>\n","      <td>0.88</td>\n","      <td>No diabetes</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>387</td>\n","      <td>226</td>\n","      <td>279</td>\n","      <td>52</td>\n","      <td>4.3</td>\n","      <td>84</td>\n","      <td>female</td>\n","      <td>60</td>\n","      <td>192</td>\n","      <td>37.5</td>\n","      <td>144</td>\n","      <td>88</td>\n","      <td>41</td>\n","      <td>48</td>\n","      <td>0.85</td>\n","      <td>Diabetes</td>\n","    </tr>\n","    <tr>\n","      <th>387</th>\n","      <td>388</td>\n","      <td>301</td>\n","      <td>90</td>\n","      <td>118</td>\n","      <td>2.6</td>\n","      <td>89</td>\n","      <td>female</td>\n","      <td>61</td>\n","      <td>115</td>\n","      <td>21.7</td>\n","      <td>218</td>\n","      <td>90</td>\n","      <td>31</td>\n","      <td>41</td>\n","      <td>0.76</td>\n","      <td>No diabetes</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>389</td>\n","      <td>232</td>\n","      <td>184</td>\n","      <td>114</td>\n","      <td>2.0</td>\n","      <td>91</td>\n","      <td>female</td>\n","      <td>61</td>\n","      <td>127</td>\n","      <td>24.0</td>\n","      <td>170</td>\n","      <td>82</td>\n","      <td>35</td>\n","      <td>38</td>\n","      <td>0.92</td>\n","      <td>Diabetes</td>\n","    </tr>\n","    <tr>\n","      <th>389</th>\n","      <td>390</td>\n","      <td>165</td>\n","      <td>94</td>\n","      <td>69</td>\n","      <td>2.4</td>\n","      <td>92</td>\n","      <td>female</td>\n","      <td>62</td>\n","      <td>217</td>\n","      <td>39.7</td>\n","      <td>160</td>\n","      <td>82</td>\n","      <td>51</td>\n","      <td>51</td>\n","      <td>1.00</td>\n","      <td>No diabetes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>390 rows Ã— 16 columns</p>\n","</div>"],"text/plain":["     Patient number  Cholesterol  Glucose  HDL Chol  Chol/HDL ratio  Age  \\\n","0                 1          193       77        49             3.9   19   \n","1                 2          146       79        41             3.6   19   \n","2                 3          217       75        54             4.0   20   \n","3                 4          226       97        70             3.2   20   \n","4                 5          164       91        67             2.4   20   \n","..              ...          ...      ...       ...             ...  ...   \n","385             386          227      105        44             5.2   83   \n","386             387          226      279        52             4.3   84   \n","387             388          301       90       118             2.6   89   \n","388             389          232      184       114             2.0   91   \n","389             390          165       94        69             2.4   92   \n","\n","     Gender  Height  Weight   BMI  Systolic BP  Diastolic BP  waist  hip  \\\n","0    female      61     119  22.5          118            70     32   38   \n","1    female      60     135  26.4          108            58     33   40   \n","2    female      67     187  29.3          110            72     40   45   \n","3    female      64     114  19.6          122            64     31   39   \n","4    female      70     141  20.2          122            86     32   39   \n","..      ...     ...     ...   ...          ...           ...    ...  ...   \n","385  female      59     125  25.2          150            90     35   40   \n","386  female      60     192  37.5          144            88     41   48   \n","387  female      61     115  21.7          218            90     31   41   \n","388  female      61     127  24.0          170            82     35   38   \n","389  female      62     217  39.7          160            82     51   51   \n","\n","     Waist/hip ratio     Diabetes  \n","0               0.84  No diabetes  \n","1               0.83  No diabetes  \n","2               0.89  No diabetes  \n","3               0.79  No diabetes  \n","4               0.82  No diabetes  \n","..               ...          ...  \n","385             0.88  No diabetes  \n","386             0.85     Diabetes  \n","387             0.76  No diabetes  \n","388             0.92     Diabetes  \n","389             1.00  No diabetes  \n","\n","[390 rows x 16 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.drop(columns=['Unnamed: 16', 'Unnamed: 17'])"]},{"cell_type":"code","execution_count":6,"id":"22fbd3f1-4dc1-497a-8668-8daa7925148f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Diabetes\n","No diabetes    0.846154\n","Diabetes       0.153846\n","Name: count, dtype: float64\n"]}],"source":["# proportion of patients with and without diabetes\n","frequency_table = df['Diabetes'].value_counts()\n","props = frequency_table.apply(lambda x: x / len(df['Diabetes']))\n","print(props)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1200x400 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Detecting Outliers\n","f = plt.figure(figsize=(12,4))\n","f.add_subplot(1,2,1)\n","df['Glucose'].plot(kind='kde')\n","f.add_subplot(1,2,2)\n","plt.boxplot(df['Glucose'])\n","plt.show()"]},{"cell_type":"code","execution_count":8,"id":"c5d22b5c-b3e7-4740-b673-4c0909108cf7","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cholesterol</th>\n","      <th>Glucose</th>\n","      <th>BMI</th>\n","      <th>Waist/hip ratio</th>\n","      <th>HDL Chol</th>\n","      <th>Chol/HDL ratio</th>\n","      <th>Systolic BP</th>\n","      <th>Diastolic BP</th>\n","      <th>Weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.319013</td>\n","      <td>-0.564655</td>\n","      <td>-0.951944</td>\n","      <td>-0.565995</td>\n","      <td>-0.073401</td>\n","      <td>-0.360132</td>\n","      <td>-0.838071</td>\n","      <td>-0.985822</td>\n","      <td>-1.447312</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-1.372619</td>\n","      <td>-0.527432</td>\n","      <td>-0.360358</td>\n","      <td>-0.702760</td>\n","      <td>-0.536983</td>\n","      <td>-0.533102</td>\n","      <td>-1.276087</td>\n","      <td>-1.875972</td>\n","      <td>-1.050840</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.218998</td>\n","      <td>-0.601879</td>\n","      <td>0.079539</td>\n","      <td>0.117828</td>\n","      <td>0.216339</td>\n","      <td>-0.302476</td>\n","      <td>-1.188484</td>\n","      <td>-0.837464</td>\n","      <td>0.237692</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.420753</td>\n","      <td>-0.192418</td>\n","      <td>-1.391841</td>\n","      <td>-1.249818</td>\n","      <td>1.143504</td>\n","      <td>-0.763729</td>\n","      <td>-0.662865</td>\n","      <td>-1.430897</td>\n","      <td>-1.571209</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.969111</td>\n","      <td>-0.304089</td>\n","      <td>-1.300828</td>\n","      <td>-0.839524</td>\n","      <td>0.969660</td>\n","      <td>-1.224982</td>\n","      <td>-0.662865</td>\n","      <td>0.201045</td>\n","      <td>-0.902163</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>385</th>\n","      <td>0.443170</td>\n","      <td>-0.043523</td>\n","      <td>-0.542385</td>\n","      <td>-0.018937</td>\n","      <td>-0.363140</td>\n","      <td>0.389404</td>\n","      <td>0.563581</td>\n","      <td>0.497761</td>\n","      <td>-1.298635</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>0.420753</td>\n","      <td>3.194941</td>\n","      <td>1.323387</td>\n","      <td>-0.429231</td>\n","      <td>0.100443</td>\n","      <td>-0.129506</td>\n","      <td>0.300771</td>\n","      <td>0.349403</td>\n","      <td>0.361590</td>\n","    </tr>\n","    <tr>\n","      <th>387</th>\n","      <td>2.102039</td>\n","      <td>-0.322701</td>\n","      <td>-1.073295</td>\n","      <td>-1.660112</td>\n","      <td>3.924999</td>\n","      <td>-1.109668</td>\n","      <td>3.542092</td>\n","      <td>0.497761</td>\n","      <td>-1.546430</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>0.555256</td>\n","      <td>1.426814</td>\n","      <td>-0.724411</td>\n","      <td>0.528122</td>\n","      <td>3.693208</td>\n","      <td>-1.455608</td>\n","      <td>1.439613</td>\n","      <td>-0.095672</td>\n","      <td>-1.249076</td>\n","    </tr>\n","    <tr>\n","      <th>389</th>\n","      <td>-0.946693</td>\n","      <td>-0.248254</td>\n","      <td>1.657102</td>\n","      <td>1.622239</td>\n","      <td>1.085556</td>\n","      <td>-1.224982</td>\n","      <td>1.001597</td>\n","      <td>-0.095672</td>\n","      <td>0.981076</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>390 rows Ã— 9 columns</p>\n","</div>"],"text/plain":["     Cholesterol   Glucose       BMI  Waist/hip ratio  HDL Chol  \\\n","0      -0.319013 -0.564655 -0.951944        -0.565995 -0.073401   \n","1      -1.372619 -0.527432 -0.360358        -0.702760 -0.536983   \n","2       0.218998 -0.601879  0.079539         0.117828  0.216339   \n","3       0.420753 -0.192418 -1.391841        -1.249818  1.143504   \n","4      -0.969111 -0.304089 -1.300828        -0.839524  0.969660   \n","..           ...       ...       ...              ...       ...   \n","385     0.443170 -0.043523 -0.542385        -0.018937 -0.363140   \n","386     0.420753  3.194941  1.323387        -0.429231  0.100443   \n","387     2.102039 -0.322701 -1.073295        -1.660112  3.924999   \n","388     0.555256  1.426814 -0.724411         0.528122  3.693208   \n","389    -0.946693 -0.248254  1.657102         1.622239  1.085556   \n","\n","     Chol/HDL ratio  Systolic BP  Diastolic BP    Weight  \n","0         -0.360132    -0.838071     -0.985822 -1.447312  \n","1         -0.533102    -1.276087     -1.875972 -1.050840  \n","2         -0.302476    -1.188484     -0.837464  0.237692  \n","3         -0.763729    -0.662865     -1.430897 -1.571209  \n","4         -1.224982    -0.662865      0.201045 -0.902163  \n","..              ...          ...           ...       ...  \n","385        0.389404     0.563581      0.497761 -1.298635  \n","386       -0.129506     0.300771      0.349403  0.361590  \n","387       -1.109668     3.542092      0.497761 -1.546430  \n","388       -1.455608     1.439613     -0.095672 -1.249076  \n","389       -1.224982     1.001597     -0.095672  0.981076  \n","\n","[390 rows x 9 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Reduce dataframe dengan cara membuat data dengan kolom yang akan digunakan saja\n","df_reduced = df[[\"Diabetes\", \"Cholesterol\", \"Glucose\", \"BMI\", \"Waist/hip ratio\", \"HDL Chol\", \"Chol/HDL ratio\", \"Systolic BP\", \"Diastolic BP\", \"Weight\"]]\n","\n","numerical_columns = df_reduced.iloc[:, 1:10]\n","\n","# Scaling data yang sudah direduce\n","scaler = StandardScaler()\n","preproc_reduced = scaler.fit(numerical_columns)\n","\n","df_standardized = preproc_reduced.transform(numerical_columns)\n","\n","# Converting the standardized array back to DataFrame\n","df_standardized = pd.DataFrame(df_standardized, columns=numerical_columns.columns)\n","df_standardized"]},{"cell_type":"code","execution_count":9,"id":"b8ba4e9b-3540-49ce-973e-f783f6a061ea","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cholesterol</th>\n","      <th>Glucose</th>\n","      <th>BMI</th>\n","      <th>Waist/hip ratio</th>\n","      <th>HDL Chol</th>\n","      <th>Chol/HDL ratio</th>\n","      <th>Systolic BP</th>\n","      <th>Diastolic BP</th>\n","      <th>Weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.900000e+02</td>\n","      <td>3.900000e+02</td>\n","      <td>3.900000e+02</td>\n","      <td>3.900000e+02</td>\n","      <td>3.900000e+02</td>\n","      <td>3.900000e+02</td>\n","      <td>3.900000e+02</td>\n","      <td>3.900000e+02</td>\n","      <td>3.900000e+02</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>7.287618e-17</td>\n","      <td>-1.457524e-16</td>\n","      <td>2.277381e-17</td>\n","      <td>-6.741046e-16</td>\n","      <td>4.327023e-17</td>\n","      <td>-6.376666e-17</td>\n","      <td>2.915047e-16</td>\n","      <td>-3.006142e-16</td>\n","      <td>-1.867452e-16</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.001285e+00</td>\n","      <td>1.001285e+00</td>\n","      <td>1.001285e+00</td>\n","      <td>1.001285e+00</td>\n","      <td>1.001285e+00</td>\n","      <td>1.001285e+00</td>\n","      <td>1.001285e+00</td>\n","      <td>1.001285e+00</td>\n","      <td>1.001285e+00</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-2.896986e+00</td>\n","      <td>-1.104399e+00</td>\n","      <td>-2.059272e+00</td>\n","      <td>-2.754229e+00</td>\n","      <td>-2.217470e+00</td>\n","      <td>-1.743891e+00</td>\n","      <td>-2.064517e+00</td>\n","      <td>-2.617764e+00</td>\n","      <td>-1.942901e+00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-6.328534e-01</td>\n","      <td>-4.902078e-01</td>\n","      <td>-7.092421e-01</td>\n","      <td>-7.027598e-01</td>\n","      <td>-7.108267e-01</td>\n","      <td>-7.637287e-01</td>\n","      <td>-6.628646e-01</td>\n","      <td>-6.149262e-01</td>\n","      <td>-6.729533e-01</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>-9.484179e-02</td>\n","      <td>-3.227011e-01</td>\n","      <td>-1.479938e-01</td>\n","      <td>-1.893664e-02</td>\n","      <td>-2.472441e-01</td>\n","      <td>-1.871623e-01</td>\n","      <td>-4.964184e-02</td>\n","      <td>-9.567210e-02</td>\n","      <td>-1.092203e-01</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>4.880041e-01</td>\n","      <td>7.659498e-03</td>\n","      <td>5.308134e-01</td>\n","      <td>6.648866e-01</td>\n","      <td>5.060777e-01</td>\n","      <td>5.047173e-01</td>\n","      <td>4.759777e-01</td>\n","      <td>4.977612e-01</td>\n","      <td>5.598254e-01</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>5.285274e+00</td>\n","      <td>5.167799e+00</td>\n","      <td>4.099291e+00</td>\n","      <td>3.536944e+00</td>\n","      <td>4.040895e+00</td>\n","      <td>8.518990e+00</td>\n","      <td>4.943744e+00</td>\n","      <td>3.019853e+00</td>\n","      <td>3.657259e+00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Cholesterol       Glucose           BMI  Waist/hip ratio  \\\n","count  3.900000e+02  3.900000e+02  3.900000e+02     3.900000e+02   \n","mean   7.287618e-17 -1.457524e-16  2.277381e-17    -6.741046e-16   \n","std    1.001285e+00  1.001285e+00  1.001285e+00     1.001285e+00   \n","min   -2.896986e+00 -1.104399e+00 -2.059272e+00    -2.754229e+00   \n","25%   -6.328534e-01 -4.902078e-01 -7.092421e-01    -7.027598e-01   \n","50%   -9.484179e-02 -3.227011e-01 -1.479938e-01    -1.893664e-02   \n","75%    4.880041e-01  7.659498e-03  5.308134e-01     6.648866e-01   \n","max    5.285274e+00  5.167799e+00  4.099291e+00     3.536944e+00   \n","\n","           HDL Chol  Chol/HDL ratio   Systolic BP  Diastolic BP        Weight  \n","count  3.900000e+02    3.900000e+02  3.900000e+02  3.900000e+02  3.900000e+02  \n","mean   4.327023e-17   -6.376666e-17  2.915047e-16 -3.006142e-16 -1.867452e-16  \n","std    1.001285e+00    1.001285e+00  1.001285e+00  1.001285e+00  1.001285e+00  \n","min   -2.217470e+00   -1.743891e+00 -2.064517e+00 -2.617764e+00 -1.942901e+00  \n","25%   -7.108267e-01   -7.637287e-01 -6.628646e-01 -6.149262e-01 -6.729533e-01  \n","50%   -2.472441e-01   -1.871623e-01 -4.964184e-02 -9.567210e-02 -1.092203e-01  \n","75%    5.060777e-01    5.047173e-01  4.759777e-01  4.977612e-01  5.598254e-01  \n","max    4.040895e+00    8.518990e+00  4.943744e+00  3.019853e+00  3.657259e+00  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df_standardized.describe()"]},{"cell_type":"markdown","id":"2c43523d-ff1e-413c-b394-4ad8e9dc9316","metadata":{},"source":["put everything in a data frame called `df_stize` and also have the labelled target (Diabetes).\n"]},{"cell_type":"code","execution_count":10,"id":"1b10d222-f93f-4284-b74e-deee26eb66a8","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Diabetes</th>\n","      <th>Cholesterol</th>\n","      <th>Glucose</th>\n","      <th>BMI</th>\n","      <th>Waist/hip ratio</th>\n","      <th>HDL Chol</th>\n","      <th>Chol/HDL ratio</th>\n","      <th>Systolic BP</th>\n","      <th>Diastolic BP</th>\n","      <th>Weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>No diabetes</td>\n","      <td>-0.319013</td>\n","      <td>-0.564655</td>\n","      <td>-0.951944</td>\n","      <td>-0.565995</td>\n","      <td>-0.073401</td>\n","      <td>-0.360132</td>\n","      <td>-0.838071</td>\n","      <td>-0.985822</td>\n","      <td>-1.447312</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>No diabetes</td>\n","      <td>-1.372619</td>\n","      <td>-0.527432</td>\n","      <td>-0.360358</td>\n","      <td>-0.702760</td>\n","      <td>-0.536983</td>\n","      <td>-0.533102</td>\n","      <td>-1.276087</td>\n","      <td>-1.875972</td>\n","      <td>-1.050840</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>No diabetes</td>\n","      <td>0.218998</td>\n","      <td>-0.601879</td>\n","      <td>0.079539</td>\n","      <td>0.117828</td>\n","      <td>0.216339</td>\n","      <td>-0.302476</td>\n","      <td>-1.188484</td>\n","      <td>-0.837464</td>\n","      <td>0.237692</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>No diabetes</td>\n","      <td>0.420753</td>\n","      <td>-0.192418</td>\n","      <td>-1.391841</td>\n","      <td>-1.249818</td>\n","      <td>1.143504</td>\n","      <td>-0.763729</td>\n","      <td>-0.662865</td>\n","      <td>-1.430897</td>\n","      <td>-1.571209</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>No diabetes</td>\n","      <td>-0.969111</td>\n","      <td>-0.304089</td>\n","      <td>-1.300828</td>\n","      <td>-0.839524</td>\n","      <td>0.969660</td>\n","      <td>-1.224982</td>\n","      <td>-0.662865</td>\n","      <td>0.201045</td>\n","      <td>-0.902163</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>385</th>\n","      <td>No diabetes</td>\n","      <td>0.443170</td>\n","      <td>-0.043523</td>\n","      <td>-0.542385</td>\n","      <td>-0.018937</td>\n","      <td>-0.363140</td>\n","      <td>0.389404</td>\n","      <td>0.563581</td>\n","      <td>0.497761</td>\n","      <td>-1.298635</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>Diabetes</td>\n","      <td>0.420753</td>\n","      <td>3.194941</td>\n","      <td>1.323387</td>\n","      <td>-0.429231</td>\n","      <td>0.100443</td>\n","      <td>-0.129506</td>\n","      <td>0.300771</td>\n","      <td>0.349403</td>\n","      <td>0.361590</td>\n","    </tr>\n","    <tr>\n","      <th>387</th>\n","      <td>No diabetes</td>\n","      <td>2.102039</td>\n","      <td>-0.322701</td>\n","      <td>-1.073295</td>\n","      <td>-1.660112</td>\n","      <td>3.924999</td>\n","      <td>-1.109668</td>\n","      <td>3.542092</td>\n","      <td>0.497761</td>\n","      <td>-1.546430</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>Diabetes</td>\n","      <td>0.555256</td>\n","      <td>1.426814</td>\n","      <td>-0.724411</td>\n","      <td>0.528122</td>\n","      <td>3.693208</td>\n","      <td>-1.455608</td>\n","      <td>1.439613</td>\n","      <td>-0.095672</td>\n","      <td>-1.249076</td>\n","    </tr>\n","    <tr>\n","      <th>389</th>\n","      <td>No diabetes</td>\n","      <td>-0.946693</td>\n","      <td>-0.248254</td>\n","      <td>1.657102</td>\n","      <td>1.622239</td>\n","      <td>1.085556</td>\n","      <td>-1.224982</td>\n","      <td>1.001597</td>\n","      <td>-0.095672</td>\n","      <td>0.981076</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>390 rows Ã— 10 columns</p>\n","</div>"],"text/plain":["        Diabetes  Cholesterol   Glucose       BMI  Waist/hip ratio  HDL Chol  \\\n","0    No diabetes    -0.319013 -0.564655 -0.951944        -0.565995 -0.073401   \n","1    No diabetes    -1.372619 -0.527432 -0.360358        -0.702760 -0.536983   \n","2    No diabetes     0.218998 -0.601879  0.079539         0.117828  0.216339   \n","3    No diabetes     0.420753 -0.192418 -1.391841        -1.249818  1.143504   \n","4    No diabetes    -0.969111 -0.304089 -1.300828        -0.839524  0.969660   \n","..           ...          ...       ...       ...              ...       ...   \n","385  No diabetes     0.443170 -0.043523 -0.542385        -0.018937 -0.363140   \n","386     Diabetes     0.420753  3.194941  1.323387        -0.429231  0.100443   \n","387  No diabetes     2.102039 -0.322701 -1.073295        -1.660112  3.924999   \n","388     Diabetes     0.555256  1.426814 -0.724411         0.528122  3.693208   \n","389  No diabetes    -0.946693 -0.248254  1.657102         1.622239  1.085556   \n","\n","     Chol/HDL ratio  Systolic BP  Diastolic BP    Weight  \n","0         -0.360132    -0.838071     -0.985822 -1.447312  \n","1         -0.533102    -1.276087     -1.875972 -1.050840  \n","2         -0.302476    -1.188484     -0.837464  0.237692  \n","3         -0.763729    -0.662865     -1.430897 -1.571209  \n","4         -1.224982    -0.662865      0.201045 -0.902163  \n","..              ...          ...           ...       ...  \n","385        0.389404     0.563581      0.497761 -1.298635  \n","386       -0.129506     0.300771      0.349403  0.361590  \n","387       -1.109668     3.542092      0.497761 -1.546430  \n","388       -1.455608     1.439613     -0.095672 -1.249076  \n","389       -1.224982     1.001597     -0.095672  0.981076  \n","\n","[390 rows x 10 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df_stdize = pd.concat([df_reduced['Diabetes'], df_standardized], axis=1)\n","df_stdize"]},{"cell_type":"markdown","id":"4260d514-8519-4ba7-a166-b03c90af6cdd","metadata":{},"source":["## Split the data set\n"]},{"cell_type":"markdown","id":"44a5ebf9-c25a-49c4-aedb-d61580c219b3","metadata":{},"source":["X is all of the features for the classification, which is all of the columns except the `Diabetes` column. Alternatively, target y is the `Diabetes` column.\n"]},{"cell_type":"code","execution_count":11,"id":"f39b9786-6d03-4d57-bd1f-2dc37c2c5a06","metadata":{},"outputs":[],"source":["X = df_stdize.drop(columns=['Diabetes'])\n","y = df_stdize['Diabetes']\n","\n","# Split the data into training and testing\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","id":"cd4ef161-e353-4bce-b53c-0313aaa15c74","metadata":{},"source":["encode those label into 0 and 1 because KNN requires numerical input. \n"]},{"cell_type":"code","execution_count":12,"id":"c8cdb13c-9bbb-44cb-a243-df853552c499","metadata":{},"outputs":[],"source":["# Initialize LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","y_train = label_encoder.fit_transform(y_train)\n","y_test = label_encoder.fit_transform(y_test)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'map'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ubah label menjadi nilai biner\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo diabetes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiabetes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m      3\u001b[0m y_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo diabetes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiabetes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n","\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'map'"]}],"source":["# Ubah label menjadi nilai biner\n","y_train = y_train.map({'No diabetes': 0, 'Diabetes': 1})\n","y_test = y_test.map({'No diabetes': 0, 'Diabetes': 1})\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------BEFORE------------\n","DecisionTreeClassifier Acc Train: [], 1 of KFold 5\n","DecisionTreeClassifier Acc Test: [], 1 of KFold 5\n","DecisionTreeClassifier Recall: [], 1 of KFold 5\n","DecisionTreeClassifier Precission: [], 1 of KFold 5\n","DecisionTreeClassifier AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","DecisionTreeClassifier Acc Train: [1.0], 1 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.9102564102564102], 1 of KFold 5\n","DecisionTreeClassifier Recall: [0.75], 1 of KFold 5\n","DecisionTreeClassifier Precission: [0.6923076923076923], 1 of KFold 5\n","DecisionTreeClassifier AUC: [0.8446969696969697], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","DecisionTreeClassifier Acc Train: [1.0], 2 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.9102564102564102], 2 of KFold 5\n","DecisionTreeClassifier Recall: [0.75], 2 of KFold 5\n","DecisionTreeClassifier Precission: [0.6923076923076923], 2 of KFold 5\n","DecisionTreeClassifier AUC: [0.8446969696969697], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0], 2 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.9102564102564102, 0.8974358974358975], 2 of KFold 5\n","DecisionTreeClassifier Recall: [0.75, 0.4166666666666667], 2 of KFold 5\n","DecisionTreeClassifier Precission: [0.6923076923076923, 0.8333333333333334], 2 of KFold 5\n","DecisionTreeClassifier AUC: [0.8446969696969697, 0.7007575757575758], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0], 3 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.9102564102564102, 0.8974358974358975], 3 of KFold 5\n","DecisionTreeClassifier Recall: [0.75, 0.4166666666666667], 3 of KFold 5\n","DecisionTreeClassifier Precission: [0.6923076923076923, 0.8333333333333334], 3 of KFold 5\n","DecisionTreeClassifier AUC: [0.8446969696969697, 0.7007575757575758], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0, 1.0], 3 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.9102564102564102, 0.8974358974358975, 0.8717948717948718], 3 of KFold 5\n","DecisionTreeClassifier Recall: [0.75, 0.4166666666666667, 0.6666666666666666], 3 of KFold 5\n","DecisionTreeClassifier Precission: [0.6923076923076923, 0.8333333333333334, 0.5714285714285714], 3 of KFold 5\n","DecisionTreeClassifier AUC: [0.8446969696969697, 0.7007575757575758, 0.7878787878787877], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0, 1.0], 4 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.9102564102564102, 0.8974358974358975, 0.8717948717948718], 4 of KFold 5\n","DecisionTreeClassifier Recall: [0.75, 0.4166666666666667, 0.6666666666666666], 4 of KFold 5\n","DecisionTreeClassifier Precission: [0.6923076923076923, 0.8333333333333334, 0.5714285714285714], 4 of KFold 5\n","DecisionTreeClassifier AUC: [0.8446969696969697, 0.7007575757575758, 0.7878787878787877], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 4 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.9102564102564102, 0.8974358974358975, 0.8717948717948718, 0.8333333333333334], 4 of KFold 5\n","DecisionTreeClassifier Recall: [0.75, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334], 4 of KFold 5\n","DecisionTreeClassifier Precission: [0.6923076923076923, 0.8333333333333334, 0.5714285714285714, 0.4666666666666667], 4 of KFold 5\n","DecisionTreeClassifier AUC: [0.8446969696969697, 0.7007575757575758, 0.7878787878787877, 0.7310606060606061], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.9102564102564102, 0.8974358974358975, 0.8717948717948718, 0.8333333333333334], 5 of KFold 5\n","DecisionTreeClassifier Recall: [0.75, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334], 5 of KFold 5\n","DecisionTreeClassifier Precission: [0.6923076923076923, 0.8333333333333334, 0.5714285714285714, 0.4666666666666667], 5 of KFold 5\n","DecisionTreeClassifier AUC: [0.8446969696969697, 0.7007575757575758, 0.7878787878787877, 0.7310606060606061], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.9102564102564102, 0.8974358974358975, 0.8717948717948718, 0.8333333333333334, 0.8717948717948718], 5 of KFold 5\n","DecisionTreeClassifier Recall: [0.75, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.3333333333333333], 5 of KFold 5\n","DecisionTreeClassifier Precission: [0.6923076923076923, 0.8333333333333334, 0.5714285714285714, 0.4666666666666667, 0.6666666666666666], 5 of KFold 5\n","DecisionTreeClassifier AUC: [0.8446969696969697, 0.7007575757575758, 0.7878787878787877, 0.7310606060606061, 0.6515151515151515], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","DecisionTreeClassifier Acc Train: 1.0\n","DecisionTreeClassifier Acc Test: 0.876923076923077\n","DecisionTreeClassifier Recall: 0.55\n","DecisionTreeClassifier Precission: 0.646080586080586\n","DecisionTreeClassifier AUC: 0.743181818181818\n","---------------------------\n","----------BEFORE------------\n","LogisticRegression Acc Train: [], 1 of KFold 5\n","LogisticRegression Acc Test: [], 1 of KFold 5\n","LogisticRegression Recall: [], 1 of KFold 5\n","LogisticRegression Precission: [], 1 of KFold 5\n","LogisticRegression AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","LogisticRegression Acc Train: [0.9262820512820513], 1 of KFold 5\n","LogisticRegression Acc Test: [0.9358974358974359], 1 of KFold 5\n","LogisticRegression Recall: [0.75], 1 of KFold 5\n","LogisticRegression Precission: [0.8181818181818182], 1 of KFold 5\n","LogisticRegression AUC: [0.8598484848484849], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","LogisticRegression Acc Train: [0.9262820512820513], 2 of KFold 5\n","LogisticRegression Acc Test: [0.9358974358974359], 2 of KFold 5\n","LogisticRegression Recall: [0.75], 2 of KFold 5\n","LogisticRegression Precission: [0.8181818181818182], 2 of KFold 5\n","LogisticRegression AUC: [0.8598484848484849], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","LogisticRegression Acc Train: [0.9262820512820513, 0.9198717948717948], 2 of KFold 5\n","LogisticRegression Acc Test: [0.9358974358974359, 0.9230769230769231], 2 of KFold 5\n","LogisticRegression Recall: [0.75, 0.5], 2 of KFold 5\n","LogisticRegression Precission: [0.8181818181818182, 1.0], 2 of KFold 5\n","LogisticRegression AUC: [0.8598484848484849, 0.75], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","LogisticRegression Acc Train: [0.9262820512820513, 0.9198717948717948], 3 of KFold 5\n","LogisticRegression Acc Test: [0.9358974358974359, 0.9230769230769231], 3 of KFold 5\n","LogisticRegression Recall: [0.75, 0.5], 3 of KFold 5\n","LogisticRegression Precission: [0.8181818181818182, 1.0], 3 of KFold 5\n","LogisticRegression AUC: [0.8598484848484849, 0.75], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","LogisticRegression Acc Train: [0.9262820512820513, 0.9198717948717948, 0.9198717948717948], 3 of KFold 5\n","LogisticRegression Acc Test: [0.9358974358974359, 0.9230769230769231, 0.9487179487179487], 3 of KFold 5\n","LogisticRegression Recall: [0.75, 0.5, 0.8333333333333334], 3 of KFold 5\n","LogisticRegression Precission: [0.8181818181818182, 1.0, 0.8333333333333334], 3 of KFold 5\n","LogisticRegression AUC: [0.8598484848484849, 0.75, 0.9015151515151516], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","LogisticRegression Acc Train: [0.9262820512820513, 0.9198717948717948, 0.9198717948717948], 4 of KFold 5\n","LogisticRegression Acc Test: [0.9358974358974359, 0.9230769230769231, 0.9487179487179487], 4 of KFold 5\n","LogisticRegression Recall: [0.75, 0.5, 0.8333333333333334], 4 of KFold 5\n","LogisticRegression Precission: [0.8181818181818182, 1.0, 0.8333333333333334], 4 of KFold 5\n","LogisticRegression AUC: [0.8598484848484849, 0.75, 0.9015151515151516], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","LogisticRegression Acc Train: [0.9262820512820513, 0.9198717948717948, 0.9198717948717948, 0.9358974358974359], 4 of KFold 5\n","LogisticRegression Acc Test: [0.9358974358974359, 0.9230769230769231, 0.9487179487179487, 0.9102564102564102], 4 of KFold 5\n","LogisticRegression Recall: [0.75, 0.5, 0.8333333333333334, 0.5], 4 of KFold 5\n","LogisticRegression Precission: [0.8181818181818182, 1.0, 0.8333333333333334, 0.8571428571428571], 4 of KFold 5\n","LogisticRegression AUC: [0.8598484848484849, 0.75, 0.9015151515151516, 0.7424242424242424], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","LogisticRegression Acc Train: [0.9262820512820513, 0.9198717948717948, 0.9198717948717948, 0.9358974358974359], 5 of KFold 5\n","LogisticRegression Acc Test: [0.9358974358974359, 0.9230769230769231, 0.9487179487179487, 0.9102564102564102], 5 of KFold 5\n","LogisticRegression Recall: [0.75, 0.5, 0.8333333333333334, 0.5], 5 of KFold 5\n","LogisticRegression Precission: [0.8181818181818182, 1.0, 0.8333333333333334, 0.8571428571428571], 5 of KFold 5\n","LogisticRegression AUC: [0.8598484848484849, 0.75, 0.9015151515151516, 0.7424242424242424], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","LogisticRegression Acc Train: [0.9262820512820513, 0.9198717948717948, 0.9198717948717948, 0.9358974358974359, 0.9230769230769231], 5 of KFold 5\n","LogisticRegression Acc Test: [0.9358974358974359, 0.9230769230769231, 0.9487179487179487, 0.9102564102564102, 0.8846153846153846], 5 of KFold 5\n","LogisticRegression Recall: [0.75, 0.5, 0.8333333333333334, 0.5, 0.25], 5 of KFold 5\n","LogisticRegression Precission: [0.8181818181818182, 1.0, 0.8333333333333334, 0.8571428571428571, 1.0], 5 of KFold 5\n","LogisticRegression AUC: [0.8598484848484849, 0.75, 0.9015151515151516, 0.7424242424242424, 0.625], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","LogisticRegression Acc Train: 0.925\n","LogisticRegression Acc Test: 0.9205128205128205\n","LogisticRegression Recall: 0.5666666666666667\n","LogisticRegression Precission: 0.9017316017316018\n","LogisticRegression AUC: 0.7757575757575758\n","---------------------------\n","----------BEFORE------------\n","KNeighborsClassifier Acc Train: [], 1 of KFold 5\n","KNeighborsClassifier Acc Test: [], 1 of KFold 5\n","KNeighborsClassifier Recall: [], 1 of KFold 5\n","KNeighborsClassifier Precission: [], 1 of KFold 5\n","KNeighborsClassifier AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","KNeighborsClassifier Acc Train: [0.9230769230769231], 1 of KFold 5\n","KNeighborsClassifier Acc Test: [0.9487179487179487], 1 of KFold 5\n","KNeighborsClassifier Recall: [0.75], 1 of KFold 5\n","KNeighborsClassifier Precission: [0.9], 1 of KFold 5\n","KNeighborsClassifier AUC: [0.8674242424242425], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","KNeighborsClassifier Acc Train: [0.9230769230769231], 2 of KFold 5\n","KNeighborsClassifier Acc Test: [0.9487179487179487], 2 of KFold 5\n","KNeighborsClassifier Recall: [0.75], 2 of KFold 5\n","KNeighborsClassifier Precission: [0.9], 2 of KFold 5\n","KNeighborsClassifier AUC: [0.8674242424242425], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","KNeighborsClassifier Acc Train: [0.9230769230769231, 0.9166666666666666], 2 of KFold 5\n","KNeighborsClassifier Acc Test: [0.9487179487179487, 0.9230769230769231], 2 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.5], 2 of KFold 5\n","KNeighborsClassifier Precission: [0.9, 1.0], 2 of KFold 5\n","KNeighborsClassifier AUC: [0.8674242424242425, 0.75], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","KNeighborsClassifier Acc Train: [0.9230769230769231, 0.9166666666666666], 3 of KFold 5\n","KNeighborsClassifier Acc Test: [0.9487179487179487, 0.9230769230769231], 3 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.5], 3 of KFold 5\n","KNeighborsClassifier Precission: [0.9, 1.0], 3 of KFold 5\n","KNeighborsClassifier AUC: [0.8674242424242425, 0.75], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","KNeighborsClassifier Acc Train: [0.9230769230769231, 0.9166666666666666, 0.9230769230769231], 3 of KFold 5\n","KNeighborsClassifier Acc Test: [0.9487179487179487, 0.9230769230769231, 0.9230769230769231], 3 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.5, 0.5], 3 of KFold 5\n","KNeighborsClassifier Precission: [0.9, 1.0, 1.0], 3 of KFold 5\n","KNeighborsClassifier AUC: [0.8674242424242425, 0.75, 0.75], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","KNeighborsClassifier Acc Train: [0.9230769230769231, 0.9166666666666666, 0.9230769230769231], 4 of KFold 5\n","KNeighborsClassifier Acc Test: [0.9487179487179487, 0.9230769230769231, 0.9230769230769231], 4 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.5, 0.5], 4 of KFold 5\n","KNeighborsClassifier Precission: [0.9, 1.0, 1.0], 4 of KFold 5\n","KNeighborsClassifier AUC: [0.8674242424242425, 0.75, 0.75], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","KNeighborsClassifier Acc Train: [0.9230769230769231, 0.9166666666666666, 0.9230769230769231, 0.9166666666666666], 4 of KFold 5\n","KNeighborsClassifier Acc Test: [0.9487179487179487, 0.9230769230769231, 0.9230769230769231, 0.8974358974358975], 4 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.5, 0.5, 0.4166666666666667], 4 of KFold 5\n","KNeighborsClassifier Precission: [0.9, 1.0, 1.0, 0.8333333333333334], 4 of KFold 5\n","KNeighborsClassifier AUC: [0.8674242424242425, 0.75, 0.75, 0.7007575757575758], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","KNeighborsClassifier Acc Train: [0.9230769230769231, 0.9166666666666666, 0.9230769230769231, 0.9166666666666666], 5 of KFold 5\n","KNeighborsClassifier Acc Test: [0.9487179487179487, 0.9230769230769231, 0.9230769230769231, 0.8974358974358975], 5 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.5, 0.5, 0.4166666666666667], 5 of KFold 5\n","KNeighborsClassifier Precission: [0.9, 1.0, 1.0, 0.8333333333333334], 5 of KFold 5\n","KNeighborsClassifier AUC: [0.8674242424242425, 0.75, 0.75, 0.7007575757575758], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","KNeighborsClassifier Acc Train: [0.9230769230769231, 0.9166666666666666, 0.9230769230769231, 0.9166666666666666, 0.9294871794871795], 5 of KFold 5\n","KNeighborsClassifier Acc Test: [0.9487179487179487, 0.9230769230769231, 0.9230769230769231, 0.8974358974358975, 0.8717948717948718], 5 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.5, 0.5, 0.4166666666666667, 0.16666666666666666], 5 of KFold 5\n","KNeighborsClassifier Precission: [0.9, 1.0, 1.0, 0.8333333333333334, 1.0], 5 of KFold 5\n","KNeighborsClassifier AUC: [0.8674242424242425, 0.75, 0.75, 0.7007575757575758, 0.5833333333333334], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","KNeighborsClassifier Acc Train: 0.9217948717948717\n","KNeighborsClassifier Acc Test: 0.9128205128205128\n","KNeighborsClassifier Recall: 0.4666666666666666\n","KNeighborsClassifier Precission: 0.9466666666666667\n","KNeighborsClassifier AUC: 0.7303030303030303\n","---------------------------\n","----------BEFORE------------\n","GaussianNB Acc Train: [], 1 of KFold 5\n","GaussianNB Acc Test: [], 1 of KFold 5\n","GaussianNB Recall: [], 1 of KFold 5\n","GaussianNB Precission: [], 1 of KFold 5\n","GaussianNB AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","GaussianNB Acc Train: [0.9230769230769231], 1 of KFold 5\n","GaussianNB Acc Test: [0.9230769230769231], 1 of KFold 5\n","GaussianNB Recall: [0.8333333333333334], 1 of KFold 5\n","GaussianNB Precission: [0.7142857142857143], 1 of KFold 5\n","GaussianNB AUC: [0.8863636363636366], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","GaussianNB Acc Train: [0.9230769230769231], 2 of KFold 5\n","GaussianNB Acc Test: [0.9230769230769231], 2 of KFold 5\n","GaussianNB Recall: [0.8333333333333334], 2 of KFold 5\n","GaussianNB Precission: [0.7142857142857143], 2 of KFold 5\n","GaussianNB AUC: [0.8863636363636366], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","GaussianNB Acc Train: [0.9230769230769231, 0.9294871794871795], 2 of KFold 5\n","GaussianNB Acc Test: [0.9230769230769231, 0.8974358974358975], 2 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.5], 2 of KFold 5\n","GaussianNB Precission: [0.7142857142857143, 0.75], 2 of KFold 5\n","GaussianNB AUC: [0.8863636363636366, 0.7348484848484849], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","GaussianNB Acc Train: [0.9230769230769231, 0.9294871794871795], 3 of KFold 5\n","GaussianNB Acc Test: [0.9230769230769231, 0.8974358974358975], 3 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.5], 3 of KFold 5\n","GaussianNB Precission: [0.7142857142857143, 0.75], 3 of KFold 5\n","GaussianNB AUC: [0.8863636363636366, 0.7348484848484849], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","GaussianNB Acc Train: [0.9230769230769231, 0.9294871794871795, 0.9198717948717948], 3 of KFold 5\n","GaussianNB Acc Test: [0.9230769230769231, 0.8974358974358975, 0.9230769230769231], 3 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.5, 0.8333333333333334], 3 of KFold 5\n","GaussianNB Precission: [0.7142857142857143, 0.75, 0.7142857142857143], 3 of KFold 5\n","GaussianNB AUC: [0.8863636363636366, 0.7348484848484849, 0.8863636363636366], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","GaussianNB Acc Train: [0.9230769230769231, 0.9294871794871795, 0.9198717948717948], 4 of KFold 5\n","GaussianNB Acc Test: [0.9230769230769231, 0.8974358974358975, 0.9230769230769231], 4 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.5, 0.8333333333333334], 4 of KFold 5\n","GaussianNB Precission: [0.7142857142857143, 0.75, 0.7142857142857143], 4 of KFold 5\n","GaussianNB AUC: [0.8863636363636366, 0.7348484848484849, 0.8863636363636366], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","GaussianNB Acc Train: [0.9230769230769231, 0.9294871794871795, 0.9198717948717948, 0.9358974358974359], 4 of KFold 5\n","GaussianNB Acc Test: [0.9230769230769231, 0.8974358974358975, 0.9230769230769231, 0.9230769230769231], 4 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.5, 0.8333333333333334, 0.75], 4 of KFold 5\n","GaussianNB Precission: [0.7142857142857143, 0.75, 0.7142857142857143, 0.75], 4 of KFold 5\n","GaussianNB AUC: [0.8863636363636366, 0.7348484848484849, 0.8863636363636366, 0.8522727272727273], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","GaussianNB Acc Train: [0.9230769230769231, 0.9294871794871795, 0.9198717948717948, 0.9358974358974359], 5 of KFold 5\n","GaussianNB Acc Test: [0.9230769230769231, 0.8974358974358975, 0.9230769230769231, 0.9230769230769231], 5 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.5, 0.8333333333333334, 0.75], 5 of KFold 5\n","GaussianNB Precission: [0.7142857142857143, 0.75, 0.7142857142857143, 0.75], 5 of KFold 5\n","GaussianNB AUC: [0.8863636363636366, 0.7348484848484849, 0.8863636363636366, 0.8522727272727273], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","GaussianNB Acc Train: [0.9230769230769231, 0.9294871794871795, 0.9198717948717948, 0.9358974358974359, 0.9230769230769231], 5 of KFold 5\n","GaussianNB Acc Test: [0.9230769230769231, 0.8974358974358975, 0.9230769230769231, 0.9230769230769231, 0.8846153846153846], 5 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.5, 0.8333333333333334, 0.75, 0.3333333333333333], 5 of KFold 5\n","GaussianNB Precission: [0.7142857142857143, 0.75, 0.7142857142857143, 0.75, 0.8], 5 of KFold 5\n","GaussianNB AUC: [0.8863636363636366, 0.7348484848484849, 0.8863636363636366, 0.8522727272727273, 0.6590909090909091], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","GaussianNB Acc Train: 0.9262820512820513\n","GaussianNB Acc Test: 0.9102564102564102\n","GaussianNB Recall: 0.6500000000000001\n","GaussianNB Precission: 0.7457142857142858\n","GaussianNB AUC: 0.8037878787878789\n","---------------------------\n","----------BEFORE------------\n","RandomForestClassifier Acc Train: [], 1 of KFold 5\n","RandomForestClassifier Acc Test: [], 1 of KFold 5\n","RandomForestClassifier Recall: [], 1 of KFold 5\n","RandomForestClassifier Precission: [], 1 of KFold 5\n","RandomForestClassifier AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","RandomForestClassifier Acc Train: [1.0], 1 of KFold 5\n","RandomForestClassifier Acc Test: [0.9230769230769231], 1 of KFold 5\n","RandomForestClassifier Recall: [0.75], 1 of KFold 5\n","RandomForestClassifier Precission: [0.75], 1 of KFold 5\n","RandomForestClassifier AUC: [0.8522727272727273], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","RandomForestClassifier Acc Train: [1.0], 2 of KFold 5\n","RandomForestClassifier Acc Test: [0.9230769230769231], 2 of KFold 5\n","RandomForestClassifier Recall: [0.75], 2 of KFold 5\n","RandomForestClassifier Precission: [0.75], 2 of KFold 5\n","RandomForestClassifier AUC: [0.8522727272727273], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","RandomForestClassifier Acc Train: [1.0, 1.0], 2 of KFold 5\n","RandomForestClassifier Acc Test: [0.9230769230769231, 0.9230769230769231], 2 of KFold 5\n","RandomForestClassifier Recall: [0.75, 0.5], 2 of KFold 5\n","RandomForestClassifier Precission: [0.75, 1.0], 2 of KFold 5\n","RandomForestClassifier AUC: [0.8522727272727273, 0.75], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","RandomForestClassifier Acc Train: [1.0, 1.0], 3 of KFold 5\n","RandomForestClassifier Acc Test: [0.9230769230769231, 0.9230769230769231], 3 of KFold 5\n","RandomForestClassifier Recall: [0.75, 0.5], 3 of KFold 5\n","RandomForestClassifier Precission: [0.75, 1.0], 3 of KFold 5\n","RandomForestClassifier AUC: [0.8522727272727273, 0.75], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","RandomForestClassifier Acc Train: [1.0, 1.0, 1.0], 3 of KFold 5\n","RandomForestClassifier Acc Test: [0.9230769230769231, 0.9230769230769231, 0.9358974358974359], 3 of KFold 5\n","RandomForestClassifier Recall: [0.75, 0.5, 0.8333333333333334], 3 of KFold 5\n","RandomForestClassifier Precission: [0.75, 1.0, 0.7692307692307693], 3 of KFold 5\n","RandomForestClassifier AUC: [0.8522727272727273, 0.75, 0.893939393939394], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","RandomForestClassifier Acc Train: [1.0, 1.0, 1.0], 4 of KFold 5\n","RandomForestClassifier Acc Test: [0.9230769230769231, 0.9230769230769231, 0.9358974358974359], 4 of KFold 5\n","RandomForestClassifier Recall: [0.75, 0.5, 0.8333333333333334], 4 of KFold 5\n","RandomForestClassifier Precission: [0.75, 1.0, 0.7692307692307693], 4 of KFold 5\n","RandomForestClassifier AUC: [0.8522727272727273, 0.75, 0.893939393939394], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","RandomForestClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 4 of KFold 5\n","RandomForestClassifier Acc Test: [0.9230769230769231, 0.9230769230769231, 0.9358974358974359, 0.8846153846153846], 4 of KFold 5\n","RandomForestClassifier Recall: [0.75, 0.5, 0.8333333333333334, 0.5], 4 of KFold 5\n","RandomForestClassifier Precission: [0.75, 1.0, 0.7692307692307693, 0.6666666666666666], 4 of KFold 5\n","RandomForestClassifier AUC: [0.8522727272727273, 0.75, 0.893939393939394, 0.7272727272727273], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","RandomForestClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","RandomForestClassifier Acc Test: [0.9230769230769231, 0.9230769230769231, 0.9358974358974359, 0.8846153846153846], 5 of KFold 5\n","RandomForestClassifier Recall: [0.75, 0.5, 0.8333333333333334, 0.5], 5 of KFold 5\n","RandomForestClassifier Precission: [0.75, 1.0, 0.7692307692307693, 0.6666666666666666], 5 of KFold 5\n","RandomForestClassifier AUC: [0.8522727272727273, 0.75, 0.893939393939394, 0.7272727272727273], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","RandomForestClassifier Acc Train: [1.0, 1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","RandomForestClassifier Acc Test: [0.9230769230769231, 0.9230769230769231, 0.9358974358974359, 0.8846153846153846, 0.8974358974358975], 5 of KFold 5\n","RandomForestClassifier Recall: [0.75, 0.5, 0.8333333333333334, 0.5, 0.3333333333333333], 5 of KFold 5\n","RandomForestClassifier Precission: [0.75, 1.0, 0.7692307692307693, 0.6666666666666666, 1.0], 5 of KFold 5\n","RandomForestClassifier AUC: [0.8522727272727273, 0.75, 0.893939393939394, 0.7272727272727273, 0.6666666666666666], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","RandomForestClassifier Acc Train: 1.0\n","RandomForestClassifier Acc Test: 0.9128205128205128\n","RandomForestClassifier Recall: 0.5833333333333334\n","RandomForestClassifier Precission: 0.8371794871794872\n","RandomForestClassifier AUC: 0.7780303030303031\n","---------------------------\n","----------BEFORE------------\n","ExtraTreesClassifier Acc Train: [], 1 of KFold 5\n","ExtraTreesClassifier Acc Test: [], 1 of KFold 5\n","ExtraTreesClassifier Recall: [], 1 of KFold 5\n","ExtraTreesClassifier Precission: [], 1 of KFold 5\n","ExtraTreesClassifier AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","ExtraTreesClassifier Acc Train: [1.0], 1 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.9230769230769231], 1 of KFold 5\n","ExtraTreesClassifier Recall: [0.75], 1 of KFold 5\n","ExtraTreesClassifier Precission: [0.75], 1 of KFold 5\n","ExtraTreesClassifier AUC: [0.8522727272727273], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","ExtraTreesClassifier Acc Train: [1.0], 2 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.9230769230769231], 2 of KFold 5\n","ExtraTreesClassifier Recall: [0.75], 2 of KFold 5\n","ExtraTreesClassifier Precission: [0.75], 2 of KFold 5\n","ExtraTreesClassifier AUC: [0.8522727272727273], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0], 2 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.9230769230769231, 0.9230769230769231], 2 of KFold 5\n","ExtraTreesClassifier Recall: [0.75, 0.5], 2 of KFold 5\n","ExtraTreesClassifier Precission: [0.75, 1.0], 2 of KFold 5\n","ExtraTreesClassifier AUC: [0.8522727272727273, 0.75], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0], 3 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.9230769230769231, 0.9230769230769231], 3 of KFold 5\n","ExtraTreesClassifier Recall: [0.75, 0.5], 3 of KFold 5\n","ExtraTreesClassifier Precission: [0.75, 1.0], 3 of KFold 5\n","ExtraTreesClassifier AUC: [0.8522727272727273, 0.75], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0, 1.0], 3 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.9230769230769231, 0.9230769230769231, 0.9230769230769231], 3 of KFold 5\n","ExtraTreesClassifier Recall: [0.75, 0.5, 0.8333333333333334], 3 of KFold 5\n","ExtraTreesClassifier Precission: [0.75, 1.0, 0.7142857142857143], 3 of KFold 5\n","ExtraTreesClassifier AUC: [0.8522727272727273, 0.75, 0.8863636363636366], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0, 1.0], 4 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.9230769230769231, 0.9230769230769231, 0.9230769230769231], 4 of KFold 5\n","ExtraTreesClassifier Recall: [0.75, 0.5, 0.8333333333333334], 4 of KFold 5\n","ExtraTreesClassifier Precission: [0.75, 1.0, 0.7142857142857143], 4 of KFold 5\n","ExtraTreesClassifier AUC: [0.8522727272727273, 0.75, 0.8863636363636366], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 4 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.9230769230769231, 0.9230769230769231, 0.9230769230769231, 0.8846153846153846], 4 of KFold 5\n","ExtraTreesClassifier Recall: [0.75, 0.5, 0.8333333333333334, 0.5], 4 of KFold 5\n","ExtraTreesClassifier Precission: [0.75, 1.0, 0.7142857142857143, 0.6666666666666666], 4 of KFold 5\n","ExtraTreesClassifier AUC: [0.8522727272727273, 0.75, 0.8863636363636366, 0.7272727272727273], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.9230769230769231, 0.9230769230769231, 0.9230769230769231, 0.8846153846153846], 5 of KFold 5\n","ExtraTreesClassifier Recall: [0.75, 0.5, 0.8333333333333334, 0.5], 5 of KFold 5\n","ExtraTreesClassifier Precission: [0.75, 1.0, 0.7142857142857143, 0.6666666666666666], 5 of KFold 5\n","ExtraTreesClassifier AUC: [0.8522727272727273, 0.75, 0.8863636363636366, 0.7272727272727273], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.9230769230769231, 0.9230769230769231, 0.9230769230769231, 0.8846153846153846, 0.8717948717948718], 5 of KFold 5\n","ExtraTreesClassifier Recall: [0.75, 0.5, 0.8333333333333334, 0.5, 0.16666666666666666], 5 of KFold 5\n","ExtraTreesClassifier Precission: [0.75, 1.0, 0.7142857142857143, 0.6666666666666666, 1.0], 5 of KFold 5\n","ExtraTreesClassifier AUC: [0.8522727272727273, 0.75, 0.8863636363636366, 0.7272727272727273, 0.5833333333333334], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","ExtraTreesClassifier Acc Train: 1.0\n","ExtraTreesClassifier Acc Test: 0.9051282051282051\n","ExtraTreesClassifier Recall: 0.55\n","ExtraTreesClassifier Precission: 0.8261904761904763\n","ExtraTreesClassifier AUC: 0.7598484848484849\n","---------------------------\n","----------BEFORE------------\n","XGBClassifier Acc Train: [], 1 of KFold 5\n","XGBClassifier Acc Test: [], 1 of KFold 5\n","XGBClassifier Recall: [], 1 of KFold 5\n","XGBClassifier Precission: [], 1 of KFold 5\n","XGBClassifier AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","XGBClassifier Acc Train: [1.0], 1 of KFold 5\n","XGBClassifier Acc Test: [0.8974358974358975], 1 of KFold 5\n","XGBClassifier Recall: [0.75], 1 of KFold 5\n","XGBClassifier Precission: [0.6428571428571429], 1 of KFold 5\n","XGBClassifier AUC: [0.8371212121212122], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","XGBClassifier Acc Train: [1.0], 2 of KFold 5\n","XGBClassifier Acc Test: [0.8974358974358975], 2 of KFold 5\n","XGBClassifier Recall: [0.75], 2 of KFold 5\n","XGBClassifier Precission: [0.6428571428571429], 2 of KFold 5\n","XGBClassifier AUC: [0.8371212121212122], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","XGBClassifier Acc Train: [1.0, 1.0], 2 of KFold 5\n","XGBClassifier Acc Test: [0.8974358974358975, 0.9102564102564102], 2 of KFold 5\n","XGBClassifier Recall: [0.75, 0.5], 2 of KFold 5\n","XGBClassifier Precission: [0.6428571428571429, 0.8571428571428571], 2 of KFold 5\n","XGBClassifier AUC: [0.8371212121212122, 0.7424242424242424], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","XGBClassifier Acc Train: [1.0, 1.0], 3 of KFold 5\n","XGBClassifier Acc Test: [0.8974358974358975, 0.9102564102564102], 3 of KFold 5\n","XGBClassifier Recall: [0.75, 0.5], 3 of KFold 5\n","XGBClassifier Precission: [0.6428571428571429, 0.8571428571428571], 3 of KFold 5\n","XGBClassifier AUC: [0.8371212121212122, 0.7424242424242424], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","XGBClassifier Acc Train: [1.0, 1.0, 1.0], 3 of KFold 5\n","XGBClassifier Acc Test: [0.8974358974358975, 0.9102564102564102, 0.9102564102564102], 3 of KFold 5\n","XGBClassifier Recall: [0.75, 0.5, 0.75], 3 of KFold 5\n","XGBClassifier Precission: [0.6428571428571429, 0.8571428571428571, 0.6923076923076923], 3 of KFold 5\n","XGBClassifier AUC: [0.8371212121212122, 0.7424242424242424, 0.8446969696969697], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","XGBClassifier Acc Train: [1.0, 1.0, 1.0], 4 of KFold 5\n","XGBClassifier Acc Test: [0.8974358974358975, 0.9102564102564102, 0.9102564102564102], 4 of KFold 5\n","XGBClassifier Recall: [0.75, 0.5, 0.75], 4 of KFold 5\n","XGBClassifier Precission: [0.6428571428571429, 0.8571428571428571, 0.6923076923076923], 4 of KFold 5\n","XGBClassifier AUC: [0.8371212121212122, 0.7424242424242424, 0.8446969696969697], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","XGBClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 4 of KFold 5\n","XGBClassifier Acc Test: [0.8974358974358975, 0.9102564102564102, 0.9102564102564102, 0.8974358974358975], 4 of KFold 5\n","XGBClassifier Recall: [0.75, 0.5, 0.75, 0.75], 4 of KFold 5\n","XGBClassifier Precission: [0.6428571428571429, 0.8571428571428571, 0.6923076923076923, 0.6428571428571429], 4 of KFold 5\n","XGBClassifier AUC: [0.8371212121212122, 0.7424242424242424, 0.8446969696969697, 0.8371212121212122], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","XGBClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","XGBClassifier Acc Test: [0.8974358974358975, 0.9102564102564102, 0.9102564102564102, 0.8974358974358975], 5 of KFold 5\n","XGBClassifier Recall: [0.75, 0.5, 0.75, 0.75], 5 of KFold 5\n","XGBClassifier Precission: [0.6428571428571429, 0.8571428571428571, 0.6923076923076923, 0.6428571428571429], 5 of KFold 5\n","XGBClassifier AUC: [0.8371212121212122, 0.7424242424242424, 0.8446969696969697, 0.8371212121212122], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","XGBClassifier Acc Train: [1.0, 1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","XGBClassifier Acc Test: [0.8974358974358975, 0.9102564102564102, 0.9102564102564102, 0.8974358974358975, 0.9358974358974359], 5 of KFold 5\n","XGBClassifier Recall: [0.75, 0.5, 0.75, 0.75, 0.5833333333333334], 5 of KFold 5\n","XGBClassifier Precission: [0.6428571428571429, 0.8571428571428571, 0.6923076923076923, 0.6428571428571429, 1.0], 5 of KFold 5\n","XGBClassifier AUC: [0.8371212121212122, 0.7424242424242424, 0.8446969696969697, 0.8371212121212122, 0.7916666666666667], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","XGBClassifier Acc Train: 1.0\n","XGBClassifier Acc Test: 0.9102564102564102\n","XGBClassifier Recall: 0.6666666666666667\n","XGBClassifier Precission: 0.7670329670329671\n","XGBClassifier AUC: 0.8106060606060608\n","---------------------------\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy training</th>\n","      <th>Accuracy test</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>AUC</th>\n","      <th>gap</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DecisionTreeClassifier</td>\n","      <td>1.000000</td>\n","      <td>0.876923</td>\n","      <td>0.646081</td>\n","      <td>0.550000</td>\n","      <td>0.743182</td>\n","      <td>0.123077</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LogisticRegression</td>\n","      <td>0.925000</td>\n","      <td>0.920513</td>\n","      <td>0.901732</td>\n","      <td>0.566667</td>\n","      <td>0.775758</td>\n","      <td>0.004487</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>KNeighborsClassifier</td>\n","      <td>0.921795</td>\n","      <td>0.912821</td>\n","      <td>0.946667</td>\n","      <td>0.466667</td>\n","      <td>0.730303</td>\n","      <td>0.008974</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GaussianNB</td>\n","      <td>0.926282</td>\n","      <td>0.910256</td>\n","      <td>0.745714</td>\n","      <td>0.650000</td>\n","      <td>0.803788</td>\n","      <td>0.016026</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>RandomForestClassifier</td>\n","      <td>1.000000</td>\n","      <td>0.912821</td>\n","      <td>0.837179</td>\n","      <td>0.583333</td>\n","      <td>0.778030</td>\n","      <td>0.087179</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>ExtraTreesClassifier</td>\n","      <td>1.000000</td>\n","      <td>0.905128</td>\n","      <td>0.826190</td>\n","      <td>0.550000</td>\n","      <td>0.759848</td>\n","      <td>0.094872</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>XGBClassifier</td>\n","      <td>1.000000</td>\n","      <td>0.910256</td>\n","      <td>0.767033</td>\n","      <td>0.666667</td>\n","      <td>0.810606</td>\n","      <td>0.089744</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    model  Accuracy training  Accuracy test  Precision  \\\n","0  DecisionTreeClassifier           1.000000       0.876923   0.646081   \n","1      LogisticRegression           0.925000       0.920513   0.901732   \n","2    KNeighborsClassifier           0.921795       0.912821   0.946667   \n","3              GaussianNB           0.926282       0.910256   0.745714   \n","4  RandomForestClassifier           1.000000       0.912821   0.837179   \n","5    ExtraTreesClassifier           1.000000       0.905128   0.826190   \n","6           XGBClassifier           1.000000       0.910256   0.767033   \n","\n","     Recall       AUC       gap  \n","0  0.550000  0.743182  0.123077  \n","1  0.566667  0.775758  0.004487  \n","2  0.466667  0.730303  0.008974  \n","3  0.650000  0.803788  0.016026  \n","4  0.583333  0.778030  0.087179  \n","5  0.550000  0.759848  0.094872  \n","6  0.666667  0.810606  0.089744  "]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# Compare model\n","data_hasil = pd.DataFrame()\n","data_hasil['model'] = model_name\n","data_hasil['Accuracy training'] = datatr\n","data_hasil['Accuracy test'] = datasc\n","data_hasil['Precision'] = Precision\n","data_hasil['Recall']= Recall\n","data_hasil['AUC']=auc\n","data_hasil['gap'] = abs(data_hasil['Accuracy training'] - data_hasil['Accuracy test'])\n","data_hasil"]},{"cell_type":"markdown","id":"b8a1b9d4-70d7-4ad7-ae92-40dec47d761b","metadata":{},"source":["## Fit the KNN model\n"]},{"cell_type":"code","execution_count":null,"id":"1a7aa467-e1dd-49f2-bae8-93c8339d3d44","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 88.46%\n"]}],"source":["# Create a KNN classifier\n","knn = KNeighborsClassifier()\n","\n","knn.fit(X_train, y_train)\n","\n","#calculate overall accuracy\n","y_pred = knn.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2%}')"]},{"cell_type":"markdown","id":"cbecf54f-2472-46b7-8204-65b955261c4e","metadata":{},"source":["## Hyperparameter tuning\n"]},{"cell_type":"markdown","id":"bc50484e-1b7a-4bc6-9718-8ffb10f5c1b6","metadata":{},"source":["## ANOVA for feature selection\n"]},{"cell_type":"markdown","id":"eb2e6af1-400e-4cdf-bc02-95ac1da261b9","metadata":{},"source":["Which features are the most important when classifying patients. ANOVA, which stands for Analysis of Variance, is a statistical method that is used to compare means across multiple groups to determine if there are any statistically significant differences between the means of these groups (glucose, cholesterol, weight, BMI, and so on). It assumes that there are no differences between the group means, and results from the hypothesis testing will tell you whether or a specific feature is significant.\n"]},{"cell_type":"code","execution_count":null,"id":"c1ec3591-2863-496f-8201-5da23c5e85e8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["           Feature     F-Score       P-Value\n","1          Glucose  350.809177  3.205119e-56\n","5   Chol/HDL ratio   31.242678  4.298115e-08\n","0      Cholesterol   16.893380  4.827353e-05\n","6      Systolic BP   15.931795  7.853024e-05\n","3  Waist/hip ratio   12.348083  4.935038e-04\n","8           Weight   10.588454  1.237749e-03\n","2              BMI    8.365055  4.040512e-03\n","4         HDL Chol    5.973355  1.496812e-02\n","7     Diastolic BP    0.947292  3.310160e-01\n"]}],"source":["fs_score, fs_p_value = f_classif(X, y)\n","\n","# Combine scores with feature names\n","fs_scores = pd.DataFrame({'Feature': X.columns, 'F-Score': fs_score, 'P-Value': fs_p_value})\n","fs_scores = fs_scores.sort_values(by='F-Score', ascending=False)\n","\n","print(fs_scores)"]},{"cell_type":"markdown","id":"fedeb34f-78b0-40f0-ac95-5ebf1bd0de56","metadata":{},"source":["'Glucose' is the most important feature in data set for predicting diabetes because its p-value is the smallest (and its F-Score is the highest).\n"]},{"cell_type":"markdown","id":"8566b6a0-ee6c-46fd-a375-bef0d7db9812","metadata":{},"source":["## Downsampling\n"]},{"cell_type":"markdown","id":"2cbbb234-6699-48ef-bd69-3e49253a5cc2","metadata":{},"source":["Begin by downsampling data set as well as having the same number of rows for diabetes positive and negative patients.\n"]},{"cell_type":"code","execution_count":16,"id":"b3066d7c-db5b-43af-a941-468e744bf2ef","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Diabetes</th>\n","      <th>Cholesterol</th>\n","      <th>Glucose</th>\n","      <th>BMI</th>\n","      <th>Waist/hip ratio</th>\n","      <th>HDL Chol</th>\n","      <th>Chol/HDL ratio</th>\n","      <th>Systolic BP</th>\n","      <th>Diastolic BP</th>\n","      <th>Weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-0.319013</td>\n","      <td>-0.564655</td>\n","      <td>-0.951944</td>\n","      <td>-0.565995</td>\n","      <td>-0.073401</td>\n","      <td>-0.360132</td>\n","      <td>-0.838071</td>\n","      <td>-0.985822</td>\n","      <td>-1.447312</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>-1.372619</td>\n","      <td>-0.527432</td>\n","      <td>-0.360358</td>\n","      <td>-0.702760</td>\n","      <td>-0.536983</td>\n","      <td>-0.533102</td>\n","      <td>-1.276087</td>\n","      <td>-1.875972</td>\n","      <td>-1.050840</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0.218998</td>\n","      <td>-0.601879</td>\n","      <td>0.079539</td>\n","      <td>0.117828</td>\n","      <td>0.216339</td>\n","      <td>-0.302476</td>\n","      <td>-1.188484</td>\n","      <td>-0.837464</td>\n","      <td>0.237692</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.420753</td>\n","      <td>-0.192418</td>\n","      <td>-1.391841</td>\n","      <td>-1.249818</td>\n","      <td>1.143504</td>\n","      <td>-0.763729</td>\n","      <td>-0.662865</td>\n","      <td>-1.430897</td>\n","      <td>-1.571209</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>-0.969111</td>\n","      <td>-0.304089</td>\n","      <td>-1.300828</td>\n","      <td>-0.839524</td>\n","      <td>0.969660</td>\n","      <td>-1.224982</td>\n","      <td>-0.662865</td>\n","      <td>0.201045</td>\n","      <td>-0.902163</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>385</th>\n","      <td>0</td>\n","      <td>0.443170</td>\n","      <td>-0.043523</td>\n","      <td>-0.542385</td>\n","      <td>-0.018937</td>\n","      <td>-0.363140</td>\n","      <td>0.389404</td>\n","      <td>0.563581</td>\n","      <td>0.497761</td>\n","      <td>-1.298635</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>1</td>\n","      <td>0.420753</td>\n","      <td>3.194941</td>\n","      <td>1.323387</td>\n","      <td>-0.429231</td>\n","      <td>0.100443</td>\n","      <td>-0.129506</td>\n","      <td>0.300771</td>\n","      <td>0.349403</td>\n","      <td>0.361590</td>\n","    </tr>\n","    <tr>\n","      <th>387</th>\n","      <td>0</td>\n","      <td>2.102039</td>\n","      <td>-0.322701</td>\n","      <td>-1.073295</td>\n","      <td>-1.660112</td>\n","      <td>3.924999</td>\n","      <td>-1.109668</td>\n","      <td>3.542092</td>\n","      <td>0.497761</td>\n","      <td>-1.546430</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>1</td>\n","      <td>0.555256</td>\n","      <td>1.426814</td>\n","      <td>-0.724411</td>\n","      <td>0.528122</td>\n","      <td>3.693208</td>\n","      <td>-1.455608</td>\n","      <td>1.439613</td>\n","      <td>-0.095672</td>\n","      <td>-1.249076</td>\n","    </tr>\n","    <tr>\n","      <th>389</th>\n","      <td>0</td>\n","      <td>-0.946693</td>\n","      <td>-0.248254</td>\n","      <td>1.657102</td>\n","      <td>1.622239</td>\n","      <td>1.085556</td>\n","      <td>-1.224982</td>\n","      <td>1.001597</td>\n","      <td>-0.095672</td>\n","      <td>0.981076</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>390 rows Ã— 10 columns</p>\n","</div>"],"text/plain":["     Diabetes  Cholesterol   Glucose       BMI  Waist/hip ratio  HDL Chol  \\\n","0           0    -0.319013 -0.564655 -0.951944        -0.565995 -0.073401   \n","1           0    -1.372619 -0.527432 -0.360358        -0.702760 -0.536983   \n","2           0     0.218998 -0.601879  0.079539         0.117828  0.216339   \n","3           0     0.420753 -0.192418 -1.391841        -1.249818  1.143504   \n","4           0    -0.969111 -0.304089 -1.300828        -0.839524  0.969660   \n","..        ...          ...       ...       ...              ...       ...   \n","385         0     0.443170 -0.043523 -0.542385        -0.018937 -0.363140   \n","386         1     0.420753  3.194941  1.323387        -0.429231  0.100443   \n","387         0     2.102039 -0.322701 -1.073295        -1.660112  3.924999   \n","388         1     0.555256  1.426814 -0.724411         0.528122  3.693208   \n","389         0    -0.946693 -0.248254  1.657102         1.622239  1.085556   \n","\n","     Chol/HDL ratio  Systolic BP  Diastolic BP    Weight  \n","0         -0.360132    -0.838071     -0.985822 -1.447312  \n","1         -0.533102    -1.276087     -1.875972 -1.050840  \n","2         -0.302476    -1.188484     -0.837464  0.237692  \n","3         -0.763729    -0.662865     -1.430897 -1.571209  \n","4         -1.224982    -0.662865      0.201045 -0.902163  \n","..              ...          ...           ...       ...  \n","385        0.389404     0.563581      0.497761 -1.298635  \n","386       -0.129506     0.300771      0.349403  0.361590  \n","387       -1.109668     3.542092      0.497761 -1.546430  \n","388       -1.455608     1.439613     -0.095672 -1.249076  \n","389       -1.224982     1.001597     -0.095672  0.981076  \n","\n","[390 rows x 10 columns]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Converting Diabetes column into binary (0 for No Diabetes and 1 for Diabetes)\n","df_stdize['Diabetes'] = np.where(df_stdize['Diabetes'] == 'Diabetes', 1, 0)\n","df_stdize"]},{"cell_type":"markdown","metadata":{},"source":["Handling Imbalance Data"]},{"cell_type":"code","execution_count":17,"id":"97056a09-3897-4675-b2d5-599508fb8b4e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of rows for positive diabetes:  60\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Diabetes</th>\n","      <th>Cholesterol</th>\n","      <th>Glucose</th>\n","      <th>BMI</th>\n","      <th>Waist/hip ratio</th>\n","      <th>HDL Chol</th>\n","      <th>Chol/HDL ratio</th>\n","      <th>Systolic BP</th>\n","      <th>Diastolic BP</th>\n","      <th>Weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>221</th>\n","      <td>0</td>\n","      <td>2.236542</td>\n","      <td>-0.378537</td>\n","      <td>-0.072149</td>\n","      <td>1.348710</td>\n","      <td>0.448130</td>\n","      <td>0.447061</td>\n","      <td>-0.750468</td>\n","      <td>-0.244030</td>\n","      <td>0.089015</td>\n","    </tr>\n","    <tr>\n","      <th>292</th>\n","      <td>0</td>\n","      <td>0.779427</td>\n","      <td>-0.471596</td>\n","      <td>-0.421034</td>\n","      <td>-0.155701</td>\n","      <td>0.216339</td>\n","      <td>-0.014192</td>\n","      <td>-0.312452</td>\n","      <td>0.497761</td>\n","      <td>-0.530471</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>0</td>\n","      <td>0.375918</td>\n","      <td>-0.415760</td>\n","      <td>0.231228</td>\n","      <td>0.254593</td>\n","      <td>-1.174409</td>\n","      <td>1.715507</td>\n","      <td>0.563581</td>\n","      <td>1.165374</td>\n","      <td>0.683723</td>\n","    </tr>\n","    <tr>\n","      <th>194</th>\n","      <td>1</td>\n","      <td>-0.005173</td>\n","      <td>1.482650</td>\n","      <td>0.413255</td>\n","      <td>0.801651</td>\n","      <td>-0.247244</td>\n","      <td>-0.014192</td>\n","      <td>0.563581</td>\n","      <td>-0.689105</td>\n","      <td>0.584605</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0</td>\n","      <td>-0.857025</td>\n","      <td>-0.062135</td>\n","      <td>0.200890</td>\n","      <td>0.938416</td>\n","      <td>0.448130</td>\n","      <td>-0.936699</td>\n","      <td>0.125565</td>\n","      <td>0.868657</td>\n","      <td>-0.580030</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Diabetes  Cholesterol   Glucose       BMI  Waist/hip ratio  HDL Chol  \\\n","221         0     2.236542 -0.378537 -0.072149         1.348710  0.448130   \n","292         0     0.779427 -0.471596 -0.421034        -0.155701  0.216339   \n","114         0     0.375918 -0.415760  0.231228         0.254593 -1.174409   \n","194         1    -0.005173  1.482650  0.413255         0.801651 -0.247244   \n","33          0    -0.857025 -0.062135  0.200890         0.938416  0.448130   \n","\n","     Chol/HDL ratio  Systolic BP  Diastolic BP    Weight  \n","221        0.447061    -0.750468     -0.244030  0.089015  \n","292       -0.014192    -0.312452      0.497761 -0.530471  \n","114        1.715507     0.563581      1.165374  0.683723  \n","194       -0.014192     0.563581     -0.689105  0.584605  \n","33        -0.936699     0.125565      0.868657 -0.580030  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Number of rows for positive diabetes\n","positive_diabetes = df_stdize[df_stdize['Diabetes'] == 1].shape[0]\n","print('Number of rows for positive diabetes: ', positive_diabetes)\n","\n","# Sample negative cases to match positive cases\n","negative_diabetes = df_stdize[df_stdize['Diabetes'] == 0]\n","negative_diabetes_downsampled = resample(negative_diabetes, replace=False, n_samples=positive_diabetes, random_state=42)\n","\n","# Put positive and negative diabetes case into one df -> balanced\n","balanced = pd.concat([negative_diabetes_downsampled, df_stdize[df_stdize['Diabetes'] == 1]])\n","balanced.sample(5)"]},{"cell_type":"markdown","id":"45e47ea3-56d2-4bf3-b956-66a6415aeca2","metadata":{},"source":["You see that the data set is now balanced below with 60 rows per category.\n"]},{"cell_type":"code","execution_count":18,"id":"6a4e07c0-7515-4742-aae6-c5b2299bd2c7","metadata":{},"outputs":[{"data":{"text/plain":["Diabetes\n","0    60\n","1    60\n","Name: count, dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["balanced['Diabetes'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["## Find Best Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = balanced[['Glucose', 'Chol/HDL ratio']]\n","y = balanced['Diabetes']\n","\n","# Split the data into training and testing\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","y_train = label_encoder.fit_transform(y_train)\n","y_test = label_encoder.fit_transform(y_test)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["#Model\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from lightgbm import LGBMClassifier\n","import xgboost\n","from xgboost import XGBClassifier\n","\n","#evaluation\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n","from sklearn.metrics import make_scorer,accuracy_score,roc_auc_score,precision_score,recall_score,f1_score,log_loss\n","from sklearn.metrics import confusion_matrix\n","\n","from sklearn.model_selection import StratifiedKFold \n","from sklearn.model_selection import RepeatedStratifiedKFold"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n","\n","all_model = [DecisionTreeClassifier,\n","            LogisticRegression,\n","             KNeighborsClassifier,\n","             GaussianNB,\n","            RandomForestClassifier,\n","            ExtraTreesClassifier,\n","             XGBClassifier]\n","\n","model_name = ['DecisionTreeClassifier',\n","            'LogisticRegression',\n","             'KNeighborsClassifier',\n","             'GaussianNB',\n","            'RandomForestClassifier',\n","            'ExtraTreesClassifier',\n","             'XGBClassifier']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------BEFORE------------\n","DecisionTreeClassifier Acc Train: [], 1 of KFold 5\n","DecisionTreeClassifier Acc Test: [], 1 of KFold 5\n","DecisionTreeClassifier Recall: [], 1 of KFold 5\n","DecisionTreeClassifier Precission: [], 1 of KFold 5\n","DecisionTreeClassifier AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","DecisionTreeClassifier Acc Train: [1.0], 1 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.75], 1 of KFold 5\n","DecisionTreeClassifier Recall: [0.8333333333333334], 1 of KFold 5\n","DecisionTreeClassifier Precission: [0.7142857142857143], 1 of KFold 5\n","DecisionTreeClassifier AUC: [0.7500000000000002], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","DecisionTreeClassifier Acc Train: [1.0], 2 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.75], 2 of KFold 5\n","DecisionTreeClassifier Recall: [0.8333333333333334], 2 of KFold 5\n","DecisionTreeClassifier Precission: [0.7142857142857143], 2 of KFold 5\n","DecisionTreeClassifier AUC: [0.7500000000000002], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0], 2 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.75, 0.8333333333333334], 2 of KFold 5\n","DecisionTreeClassifier Recall: [0.8333333333333334, 0.8333333333333334], 2 of KFold 5\n","DecisionTreeClassifier Precission: [0.7142857142857143, 0.8333333333333334], 2 of KFold 5\n","DecisionTreeClassifier AUC: [0.7500000000000002, 0.8333333333333334], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0], 3 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.75, 0.8333333333333334], 3 of KFold 5\n","DecisionTreeClassifier Recall: [0.8333333333333334, 0.8333333333333334], 3 of KFold 5\n","DecisionTreeClassifier Precission: [0.7142857142857143, 0.8333333333333334], 3 of KFold 5\n","DecisionTreeClassifier AUC: [0.7500000000000002, 0.8333333333333334], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0, 1.0], 3 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.75, 0.8333333333333334, 0.7916666666666666], 3 of KFold 5\n","DecisionTreeClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666], 3 of KFold 5\n","DecisionTreeClassifier Precission: [0.7142857142857143, 0.8333333333333334, 0.8888888888888888], 3 of KFold 5\n","DecisionTreeClassifier AUC: [0.7500000000000002, 0.8333333333333334, 0.7916666666666666], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0, 1.0], 4 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.75, 0.8333333333333334, 0.7916666666666666], 4 of KFold 5\n","DecisionTreeClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666], 4 of KFold 5\n","DecisionTreeClassifier Precission: [0.7142857142857143, 0.8333333333333334, 0.8888888888888888], 4 of KFold 5\n","DecisionTreeClassifier AUC: [0.7500000000000002, 0.8333333333333334, 0.7916666666666666], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 4 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.75, 0.8333333333333334, 0.7916666666666666, 0.8333333333333334], 4 of KFold 5\n","DecisionTreeClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 1.0], 4 of KFold 5\n","DecisionTreeClassifier Precission: [0.7142857142857143, 0.8333333333333334, 0.8888888888888888, 0.75], 4 of KFold 5\n","DecisionTreeClassifier AUC: [0.7500000000000002, 0.8333333333333334, 0.7916666666666666, 0.8333333333333334], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.75, 0.8333333333333334, 0.7916666666666666, 0.8333333333333334], 5 of KFold 5\n","DecisionTreeClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 1.0], 5 of KFold 5\n","DecisionTreeClassifier Precission: [0.7142857142857143, 0.8333333333333334, 0.8888888888888888, 0.75], 5 of KFold 5\n","DecisionTreeClassifier AUC: [0.7500000000000002, 0.8333333333333334, 0.7916666666666666, 0.8333333333333334], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","DecisionTreeClassifier Acc Train: [1.0, 1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","DecisionTreeClassifier Acc Test: [0.75, 0.8333333333333334, 0.7916666666666666, 0.8333333333333334, 0.7083333333333334], 5 of KFold 5\n","DecisionTreeClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 1.0, 0.5833333333333334], 5 of KFold 5\n","DecisionTreeClassifier Precission: [0.7142857142857143, 0.8333333333333334, 0.8888888888888888, 0.75, 0.7777777777777778], 5 of KFold 5\n","DecisionTreeClassifier AUC: [0.7500000000000002, 0.8333333333333334, 0.7916666666666666, 0.8333333333333334, 0.7083333333333335], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","DecisionTreeClassifier Acc Train: 1.0\n","DecisionTreeClassifier Acc Test: 0.7833333333333334\n","DecisionTreeClassifier Recall: 0.7833333333333334\n","DecisionTreeClassifier Precission: 0.7928571428571429\n","DecisionTreeClassifier AUC: 0.7833333333333334\n","---------------------------\n","----------BEFORE------------\n","LogisticRegression Acc Train: [], 1 of KFold 5\n","LogisticRegression Acc Test: [], 1 of KFold 5\n","LogisticRegression Recall: [], 1 of KFold 5\n","LogisticRegression Precission: [], 1 of KFold 5\n","LogisticRegression AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","LogisticRegression Acc Train: [0.8645833333333334], 1 of KFold 5\n","LogisticRegression Acc Test: [0.7916666666666666], 1 of KFold 5\n","LogisticRegression Recall: [0.8333333333333334], 1 of KFold 5\n","LogisticRegression Precission: [0.7692307692307693], 1 of KFold 5\n","LogisticRegression AUC: [0.7916666666666666], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","LogisticRegression Acc Train: [0.8645833333333334], 2 of KFold 5\n","LogisticRegression Acc Test: [0.7916666666666666], 2 of KFold 5\n","LogisticRegression Recall: [0.8333333333333334], 2 of KFold 5\n","LogisticRegression Precission: [0.7692307692307693], 2 of KFold 5\n","LogisticRegression AUC: [0.7916666666666666], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","LogisticRegression Acc Train: [0.8645833333333334, 0.8645833333333334], 2 of KFold 5\n","LogisticRegression Acc Test: [0.7916666666666666, 0.9166666666666666], 2 of KFold 5\n","LogisticRegression Recall: [0.8333333333333334, 0.8333333333333334], 2 of KFold 5\n","LogisticRegression Precission: [0.7692307692307693, 1.0], 2 of KFold 5\n","LogisticRegression AUC: [0.7916666666666666, 0.9166666666666667], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","LogisticRegression Acc Train: [0.8645833333333334, 0.8645833333333334], 3 of KFold 5\n","LogisticRegression Acc Test: [0.7916666666666666, 0.9166666666666666], 3 of KFold 5\n","LogisticRegression Recall: [0.8333333333333334, 0.8333333333333334], 3 of KFold 5\n","LogisticRegression Precission: [0.7692307692307693, 1.0], 3 of KFold 5\n","LogisticRegression AUC: [0.7916666666666666, 0.9166666666666667], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","LogisticRegression Acc Train: [0.8645833333333334, 0.8645833333333334, 0.875], 3 of KFold 5\n","LogisticRegression Acc Test: [0.7916666666666666, 0.9166666666666666, 0.875], 3 of KFold 5\n","LogisticRegression Recall: [0.8333333333333334, 0.8333333333333334, 0.75], 3 of KFold 5\n","LogisticRegression Precission: [0.7692307692307693, 1.0, 1.0], 3 of KFold 5\n","LogisticRegression AUC: [0.7916666666666666, 0.9166666666666667, 0.875], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","LogisticRegression Acc Train: [0.8645833333333334, 0.8645833333333334, 0.875], 4 of KFold 5\n","LogisticRegression Acc Test: [0.7916666666666666, 0.9166666666666666, 0.875], 4 of KFold 5\n","LogisticRegression Recall: [0.8333333333333334, 0.8333333333333334, 0.75], 4 of KFold 5\n","LogisticRegression Precission: [0.7692307692307693, 1.0, 1.0], 4 of KFold 5\n","LogisticRegression AUC: [0.7916666666666666, 0.9166666666666667, 0.875], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","LogisticRegression Acc Train: [0.8645833333333334, 0.8645833333333334, 0.875, 0.8541666666666666], 4 of KFold 5\n","LogisticRegression Acc Test: [0.7916666666666666, 0.9166666666666666, 0.875, 0.9583333333333334], 4 of KFold 5\n","LogisticRegression Recall: [0.8333333333333334, 0.8333333333333334, 0.75, 0.9166666666666666], 4 of KFold 5\n","LogisticRegression Precission: [0.7692307692307693, 1.0, 1.0, 1.0], 4 of KFold 5\n","LogisticRegression AUC: [0.7916666666666666, 0.9166666666666667, 0.875, 0.9583333333333333], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","LogisticRegression Acc Train: [0.8645833333333334, 0.8645833333333334, 0.875, 0.8541666666666666], 5 of KFold 5\n","LogisticRegression Acc Test: [0.7916666666666666, 0.9166666666666666, 0.875, 0.9583333333333334], 5 of KFold 5\n","LogisticRegression Recall: [0.8333333333333334, 0.8333333333333334, 0.75, 0.9166666666666666], 5 of KFold 5\n","LogisticRegression Precission: [0.7692307692307693, 1.0, 1.0, 1.0], 5 of KFold 5\n","LogisticRegression AUC: [0.7916666666666666, 0.9166666666666667, 0.875, 0.9583333333333333], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","LogisticRegression Acc Train: [0.8645833333333334, 0.8645833333333334, 0.875, 0.8541666666666666, 0.90625], 5 of KFold 5\n","LogisticRegression Acc Test: [0.7916666666666666, 0.9166666666666666, 0.875, 0.9583333333333334, 0.75], 5 of KFold 5\n","LogisticRegression Recall: [0.8333333333333334, 0.8333333333333334, 0.75, 0.9166666666666666, 0.5833333333333334], 5 of KFold 5\n","LogisticRegression Precission: [0.7692307692307693, 1.0, 1.0, 1.0, 0.875], 5 of KFold 5\n","LogisticRegression AUC: [0.7916666666666666, 0.9166666666666667, 0.875, 0.9583333333333333, 0.7500000000000001], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","LogisticRegression Acc Train: 0.8729166666666668\n","LogisticRegression Acc Test: 0.8583333333333332\n","LogisticRegression Recall: 0.7833333333333334\n","LogisticRegression Precission: 0.9288461538461539\n","LogisticRegression AUC: 0.8583333333333334\n","---------------------------\n","----------BEFORE------------\n","KNeighborsClassifier Acc Train: [], 1 of KFold 5\n","KNeighborsClassifier Acc Test: [], 1 of KFold 5\n","KNeighborsClassifier Recall: [], 1 of KFold 5\n","KNeighborsClassifier Precission: [], 1 of KFold 5\n","KNeighborsClassifier AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","KNeighborsClassifier Acc Train: [0.90625], 1 of KFold 5\n","KNeighborsClassifier Acc Test: [0.6666666666666666], 1 of KFold 5\n","KNeighborsClassifier Recall: [0.75], 1 of KFold 5\n","KNeighborsClassifier Precission: [0.6428571428571429], 1 of KFold 5\n","KNeighborsClassifier AUC: [0.6666666666666666], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","KNeighborsClassifier Acc Train: [0.90625], 2 of KFold 5\n","KNeighborsClassifier Acc Test: [0.6666666666666666], 2 of KFold 5\n","KNeighborsClassifier Recall: [0.75], 2 of KFold 5\n","KNeighborsClassifier Precission: [0.6428571428571429], 2 of KFold 5\n","KNeighborsClassifier AUC: [0.6666666666666666], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","KNeighborsClassifier Acc Train: [0.90625, 0.8958333333333334], 2 of KFold 5\n","KNeighborsClassifier Acc Test: [0.6666666666666666, 0.8333333333333334], 2 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.8333333333333334], 2 of KFold 5\n","KNeighborsClassifier Precission: [0.6428571428571429, 0.8333333333333334], 2 of KFold 5\n","KNeighborsClassifier AUC: [0.6666666666666666, 0.8333333333333334], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","KNeighborsClassifier Acc Train: [0.90625, 0.8958333333333334], 3 of KFold 5\n","KNeighborsClassifier Acc Test: [0.6666666666666666, 0.8333333333333334], 3 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.8333333333333334], 3 of KFold 5\n","KNeighborsClassifier Precission: [0.6428571428571429, 0.8333333333333334], 3 of KFold 5\n","KNeighborsClassifier AUC: [0.6666666666666666, 0.8333333333333334], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","KNeighborsClassifier Acc Train: [0.90625, 0.8958333333333334, 0.8645833333333334], 3 of KFold 5\n","KNeighborsClassifier Acc Test: [0.6666666666666666, 0.8333333333333334, 0.7083333333333334], 3 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.8333333333333334, 0.5833333333333334], 3 of KFold 5\n","KNeighborsClassifier Precission: [0.6428571428571429, 0.8333333333333334, 0.7777777777777778], 3 of KFold 5\n","KNeighborsClassifier AUC: [0.6666666666666666, 0.8333333333333334, 0.7083333333333335], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","KNeighborsClassifier Acc Train: [0.90625, 0.8958333333333334, 0.8645833333333334], 4 of KFold 5\n","KNeighborsClassifier Acc Test: [0.6666666666666666, 0.8333333333333334, 0.7083333333333334], 4 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.8333333333333334, 0.5833333333333334], 4 of KFold 5\n","KNeighborsClassifier Precission: [0.6428571428571429, 0.8333333333333334, 0.7777777777777778], 4 of KFold 5\n","KNeighborsClassifier AUC: [0.6666666666666666, 0.8333333333333334, 0.7083333333333335], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","KNeighborsClassifier Acc Train: [0.90625, 0.8958333333333334, 0.8645833333333334, 0.8333333333333334], 4 of KFold 5\n","KNeighborsClassifier Acc Test: [0.6666666666666666, 0.8333333333333334, 0.7083333333333334, 0.9583333333333334], 4 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.8333333333333334, 0.5833333333333334, 0.9166666666666666], 4 of KFold 5\n","KNeighborsClassifier Precission: [0.6428571428571429, 0.8333333333333334, 0.7777777777777778, 1.0], 4 of KFold 5\n","KNeighborsClassifier AUC: [0.6666666666666666, 0.8333333333333334, 0.7083333333333335, 0.9583333333333333], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","KNeighborsClassifier Acc Train: [0.90625, 0.8958333333333334, 0.8645833333333334, 0.8333333333333334], 5 of KFold 5\n","KNeighborsClassifier Acc Test: [0.6666666666666666, 0.8333333333333334, 0.7083333333333334, 0.9583333333333334], 5 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.8333333333333334, 0.5833333333333334, 0.9166666666666666], 5 of KFold 5\n","KNeighborsClassifier Precission: [0.6428571428571429, 0.8333333333333334, 0.7777777777777778, 1.0], 5 of KFold 5\n","KNeighborsClassifier AUC: [0.6666666666666666, 0.8333333333333334, 0.7083333333333335, 0.9583333333333333], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","KNeighborsClassifier Acc Train: [0.90625, 0.8958333333333334, 0.8645833333333334, 0.8333333333333334, 0.8958333333333334], 5 of KFold 5\n","KNeighborsClassifier Acc Test: [0.6666666666666666, 0.8333333333333334, 0.7083333333333334, 0.9583333333333334, 0.75], 5 of KFold 5\n","KNeighborsClassifier Recall: [0.75, 0.8333333333333334, 0.5833333333333334, 0.9166666666666666, 0.5833333333333334], 5 of KFold 5\n","KNeighborsClassifier Precission: [0.6428571428571429, 0.8333333333333334, 0.7777777777777778, 1.0, 0.875], 5 of KFold 5\n","KNeighborsClassifier AUC: [0.6666666666666666, 0.8333333333333334, 0.7083333333333335, 0.9583333333333333, 0.7500000000000001], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","KNeighborsClassifier Acc Train: 0.8791666666666668\n","KNeighborsClassifier Acc Test: 0.7833333333333334\n","KNeighborsClassifier Recall: 0.7333333333333334\n","KNeighborsClassifier Precission: 0.8257936507936507\n","KNeighborsClassifier AUC: 0.7833333333333334\n","---------------------------\n","----------BEFORE------------\n","GaussianNB Acc Train: [], 1 of KFold 5\n","GaussianNB Acc Test: [], 1 of KFold 5\n","GaussianNB Recall: [], 1 of KFold 5\n","GaussianNB Precission: [], 1 of KFold 5\n","GaussianNB AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","GaussianNB Acc Train: [0.8541666666666666], 1 of KFold 5\n","GaussianNB Acc Test: [0.7916666666666666], 1 of KFold 5\n","GaussianNB Recall: [0.8333333333333334], 1 of KFold 5\n","GaussianNB Precission: [0.7692307692307693], 1 of KFold 5\n","GaussianNB AUC: [0.7916666666666666], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","GaussianNB Acc Train: [0.8541666666666666], 2 of KFold 5\n","GaussianNB Acc Test: [0.7916666666666666], 2 of KFold 5\n","GaussianNB Recall: [0.8333333333333334], 2 of KFold 5\n","GaussianNB Precission: [0.7692307692307693], 2 of KFold 5\n","GaussianNB AUC: [0.7916666666666666], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","GaussianNB Acc Train: [0.8541666666666666, 0.7916666666666666], 2 of KFold 5\n","GaussianNB Acc Test: [0.7916666666666666, 0.9166666666666666], 2 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.8333333333333334], 2 of KFold 5\n","GaussianNB Precission: [0.7692307692307693, 1.0], 2 of KFold 5\n","GaussianNB AUC: [0.7916666666666666, 0.9166666666666667], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","GaussianNB Acc Train: [0.8541666666666666, 0.7916666666666666], 3 of KFold 5\n","GaussianNB Acc Test: [0.7916666666666666, 0.9166666666666666], 3 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.8333333333333334], 3 of KFold 5\n","GaussianNB Precission: [0.7692307692307693, 1.0], 3 of KFold 5\n","GaussianNB AUC: [0.7916666666666666, 0.9166666666666667], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","GaussianNB Acc Train: [0.8541666666666666, 0.7916666666666666, 0.8125], 3 of KFold 5\n","GaussianNB Acc Test: [0.7916666666666666, 0.9166666666666666, 0.8333333333333334], 3 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666], 3 of KFold 5\n","GaussianNB Precission: [0.7692307692307693, 1.0, 1.0], 3 of KFold 5\n","GaussianNB AUC: [0.7916666666666666, 0.9166666666666667, 0.8333333333333333], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","GaussianNB Acc Train: [0.8541666666666666, 0.7916666666666666, 0.8125], 4 of KFold 5\n","GaussianNB Acc Test: [0.7916666666666666, 0.9166666666666666, 0.8333333333333334], 4 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666], 4 of KFold 5\n","GaussianNB Precission: [0.7692307692307693, 1.0, 1.0], 4 of KFold 5\n","GaussianNB AUC: [0.7916666666666666, 0.9166666666666667, 0.8333333333333333], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","GaussianNB Acc Train: [0.8541666666666666, 0.7916666666666666, 0.8125, 0.8020833333333334], 4 of KFold 5\n","GaussianNB Acc Test: [0.7916666666666666, 0.9166666666666666, 0.8333333333333334, 0.875], 4 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 0.8333333333333334], 4 of KFold 5\n","GaussianNB Precission: [0.7692307692307693, 1.0, 1.0, 0.9090909090909091], 4 of KFold 5\n","GaussianNB AUC: [0.7916666666666666, 0.9166666666666667, 0.8333333333333333, 0.875], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","GaussianNB Acc Train: [0.8541666666666666, 0.7916666666666666, 0.8125, 0.8020833333333334], 5 of KFold 5\n","GaussianNB Acc Test: [0.7916666666666666, 0.9166666666666666, 0.8333333333333334, 0.875], 5 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 0.8333333333333334], 5 of KFold 5\n","GaussianNB Precission: [0.7692307692307693, 1.0, 1.0, 0.9090909090909091], 5 of KFold 5\n","GaussianNB AUC: [0.7916666666666666, 0.9166666666666667, 0.8333333333333333, 0.875], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","GaussianNB Acc Train: [0.8541666666666666, 0.7916666666666666, 0.8125, 0.8020833333333334, 0.84375], 5 of KFold 5\n","GaussianNB Acc Test: [0.7916666666666666, 0.9166666666666666, 0.8333333333333334, 0.875, 0.7083333333333334], 5 of KFold 5\n","GaussianNB Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 0.8333333333333334, 0.5], 5 of KFold 5\n","GaussianNB Precission: [0.7692307692307693, 1.0, 1.0, 0.9090909090909091, 0.8571428571428571], 5 of KFold 5\n","GaussianNB AUC: [0.7916666666666666, 0.9166666666666667, 0.8333333333333333, 0.875, 0.7083333333333334], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","GaussianNB Acc Train: 0.8208333333333332\n","GaussianNB Acc Test: 0.825\n","GaussianNB Recall: 0.7333333333333334\n","GaussianNB Precission: 0.907092907092907\n","GaussianNB AUC: 0.825\n","---------------------------\n","----------BEFORE------------\n","RandomForestClassifier Acc Train: [], 1 of KFold 5\n","RandomForestClassifier Acc Test: [], 1 of KFold 5\n","RandomForestClassifier Recall: [], 1 of KFold 5\n","RandomForestClassifier Precission: [], 1 of KFold 5\n","RandomForestClassifier AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","RandomForestClassifier Acc Train: [1.0], 1 of KFold 5\n","RandomForestClassifier Acc Test: [0.7916666666666666], 1 of KFold 5\n","RandomForestClassifier Recall: [0.8333333333333334], 1 of KFold 5\n","RandomForestClassifier Precission: [0.7692307692307693], 1 of KFold 5\n","RandomForestClassifier AUC: [0.7916666666666666], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","RandomForestClassifier Acc Train: [1.0], 2 of KFold 5\n","RandomForestClassifier Acc Test: [0.7916666666666666], 2 of KFold 5\n","RandomForestClassifier Recall: [0.8333333333333334], 2 of KFold 5\n","RandomForestClassifier Precission: [0.7692307692307693], 2 of KFold 5\n","RandomForestClassifier AUC: [0.7916666666666666], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","RandomForestClassifier Acc Train: [1.0, 1.0], 2 of KFold 5\n","RandomForestClassifier Acc Test: [0.7916666666666666, 0.7916666666666666], 2 of KFold 5\n","RandomForestClassifier Recall: [0.8333333333333334, 0.8333333333333334], 2 of KFold 5\n","RandomForestClassifier Precission: [0.7692307692307693, 0.7692307692307693], 2 of KFold 5\n","RandomForestClassifier AUC: [0.7916666666666666, 0.7916666666666666], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","RandomForestClassifier Acc Train: [1.0, 1.0], 3 of KFold 5\n","RandomForestClassifier Acc Test: [0.7916666666666666, 0.7916666666666666], 3 of KFold 5\n","RandomForestClassifier Recall: [0.8333333333333334, 0.8333333333333334], 3 of KFold 5\n","RandomForestClassifier Precission: [0.7692307692307693, 0.7692307692307693], 3 of KFold 5\n","RandomForestClassifier AUC: [0.7916666666666666, 0.7916666666666666], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","RandomForestClassifier Acc Train: [1.0, 1.0, 1.0], 3 of KFold 5\n","RandomForestClassifier Acc Test: [0.7916666666666666, 0.7916666666666666, 0.8333333333333334], 3 of KFold 5\n","RandomForestClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.75], 3 of KFold 5\n","RandomForestClassifier Precission: [0.7692307692307693, 0.7692307692307693, 0.9], 3 of KFold 5\n","RandomForestClassifier AUC: [0.7916666666666666, 0.7916666666666666, 0.8333333333333333], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","RandomForestClassifier Acc Train: [1.0, 1.0, 1.0], 4 of KFold 5\n","RandomForestClassifier Acc Test: [0.7916666666666666, 0.7916666666666666, 0.8333333333333334], 4 of KFold 5\n","RandomForestClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.75], 4 of KFold 5\n","RandomForestClassifier Precission: [0.7692307692307693, 0.7692307692307693, 0.9], 4 of KFold 5\n","RandomForestClassifier AUC: [0.7916666666666666, 0.7916666666666666, 0.8333333333333333], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","RandomForestClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 4 of KFold 5\n","RandomForestClassifier Acc Test: [0.7916666666666666, 0.7916666666666666, 0.8333333333333334, 1.0], 4 of KFold 5\n","RandomForestClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.75, 1.0], 4 of KFold 5\n","RandomForestClassifier Precission: [0.7692307692307693, 0.7692307692307693, 0.9, 1.0], 4 of KFold 5\n","RandomForestClassifier AUC: [0.7916666666666666, 0.7916666666666666, 0.8333333333333333, 1.0], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","RandomForestClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","RandomForestClassifier Acc Test: [0.7916666666666666, 0.7916666666666666, 0.8333333333333334, 1.0], 5 of KFold 5\n","RandomForestClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.75, 1.0], 5 of KFold 5\n","RandomForestClassifier Precission: [0.7692307692307693, 0.7692307692307693, 0.9, 1.0], 5 of KFold 5\n","RandomForestClassifier AUC: [0.7916666666666666, 0.7916666666666666, 0.8333333333333333, 1.0], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","RandomForestClassifier Acc Train: [1.0, 1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","RandomForestClassifier Acc Test: [0.7916666666666666, 0.7916666666666666, 0.8333333333333334, 1.0, 0.7916666666666666], 5 of KFold 5\n","RandomForestClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.75, 1.0, 0.75], 5 of KFold 5\n","RandomForestClassifier Precission: [0.7692307692307693, 0.7692307692307693, 0.9, 1.0, 0.8181818181818182], 5 of KFold 5\n","RandomForestClassifier AUC: [0.7916666666666666, 0.7916666666666666, 0.8333333333333333, 1.0, 0.7916666666666667], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","RandomForestClassifier Acc Train: 1.0\n","RandomForestClassifier Acc Test: 0.8416666666666666\n","RandomForestClassifier Recall: 0.8333333333333334\n","RandomForestClassifier Precission: 0.8513286713286714\n","RandomForestClassifier AUC: 0.8416666666666666\n","---------------------------\n","----------BEFORE------------\n","ExtraTreesClassifier Acc Train: [], 1 of KFold 5\n","ExtraTreesClassifier Acc Test: [], 1 of KFold 5\n","ExtraTreesClassifier Recall: [], 1 of KFold 5\n","ExtraTreesClassifier Precission: [], 1 of KFold 5\n","ExtraTreesClassifier AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","ExtraTreesClassifier Acc Train: [1.0], 1 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.75], 1 of KFold 5\n","ExtraTreesClassifier Recall: [0.8333333333333334], 1 of KFold 5\n","ExtraTreesClassifier Precission: [0.7142857142857143], 1 of KFold 5\n","ExtraTreesClassifier AUC: [0.7500000000000002], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","ExtraTreesClassifier Acc Train: [1.0], 2 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.75], 2 of KFold 5\n","ExtraTreesClassifier Recall: [0.8333333333333334], 2 of KFold 5\n","ExtraTreesClassifier Precission: [0.7142857142857143], 2 of KFold 5\n","ExtraTreesClassifier AUC: [0.7500000000000002], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0], 2 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.75, 0.8333333333333334], 2 of KFold 5\n","ExtraTreesClassifier Recall: [0.8333333333333334, 0.8333333333333334], 2 of KFold 5\n","ExtraTreesClassifier Precission: [0.7142857142857143, 0.8333333333333334], 2 of KFold 5\n","ExtraTreesClassifier AUC: [0.7500000000000002, 0.8333333333333334], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0], 3 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.75, 0.8333333333333334], 3 of KFold 5\n","ExtraTreesClassifier Recall: [0.8333333333333334, 0.8333333333333334], 3 of KFold 5\n","ExtraTreesClassifier Precission: [0.7142857142857143, 0.8333333333333334], 3 of KFold 5\n","ExtraTreesClassifier AUC: [0.7500000000000002, 0.8333333333333334], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0, 1.0], 3 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.75, 0.8333333333333334, 0.75], 3 of KFold 5\n","ExtraTreesClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666], 3 of KFold 5\n","ExtraTreesClassifier Precission: [0.7142857142857143, 0.8333333333333334, 0.8], 3 of KFold 5\n","ExtraTreesClassifier AUC: [0.7500000000000002, 0.8333333333333334, 0.75], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0, 1.0], 4 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.75, 0.8333333333333334, 0.75], 4 of KFold 5\n","ExtraTreesClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666], 4 of KFold 5\n","ExtraTreesClassifier Precission: [0.7142857142857143, 0.8333333333333334, 0.8], 4 of KFold 5\n","ExtraTreesClassifier AUC: [0.7500000000000002, 0.8333333333333334, 0.75], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 4 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.75, 0.8333333333333334, 0.75, 1.0], 4 of KFold 5\n","ExtraTreesClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 1.0], 4 of KFold 5\n","ExtraTreesClassifier Precission: [0.7142857142857143, 0.8333333333333334, 0.8, 1.0], 4 of KFold 5\n","ExtraTreesClassifier AUC: [0.7500000000000002, 0.8333333333333334, 0.75, 1.0], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.75, 0.8333333333333334, 0.75, 1.0], 5 of KFold 5\n","ExtraTreesClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 1.0], 5 of KFold 5\n","ExtraTreesClassifier Precission: [0.7142857142857143, 0.8333333333333334, 0.8, 1.0], 5 of KFold 5\n","ExtraTreesClassifier AUC: [0.7500000000000002, 0.8333333333333334, 0.75, 1.0], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","ExtraTreesClassifier Acc Train: [1.0, 1.0, 1.0, 1.0, 1.0], 5 of KFold 5\n","ExtraTreesClassifier Acc Test: [0.75, 0.8333333333333334, 0.75, 1.0, 0.7916666666666666], 5 of KFold 5\n","ExtraTreesClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 1.0, 0.6666666666666666], 5 of KFold 5\n","ExtraTreesClassifier Precission: [0.7142857142857143, 0.8333333333333334, 0.8, 1.0, 0.8888888888888888], 5 of KFold 5\n","ExtraTreesClassifier AUC: [0.7500000000000002, 0.8333333333333334, 0.75, 1.0, 0.7916666666666666], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","ExtraTreesClassifier Acc Train: 1.0\n","ExtraTreesClassifier Acc Test: 0.825\n","ExtraTreesClassifier Recall: 0.8\n","ExtraTreesClassifier Precission: 0.8473015873015873\n","ExtraTreesClassifier AUC: 0.825\n","---------------------------\n","----------BEFORE------------\n","XGBClassifier Acc Train: [], 1 of KFold 5\n","XGBClassifier Acc Test: [], 1 of KFold 5\n","XGBClassifier Recall: [], 1 of KFold 5\n","XGBClassifier Precission: [], 1 of KFold 5\n","XGBClassifier AUC: [], 1 of KFold 5\n","---------------------------\n","----------AFTER------------\n","XGBClassifier Acc Train: [0.9895833333333334], 1 of KFold 5\n","XGBClassifier Acc Test: [0.75], 1 of KFold 5\n","XGBClassifier Recall: [0.8333333333333334], 1 of KFold 5\n","XGBClassifier Precission: [0.7142857142857143], 1 of KFold 5\n","XGBClassifier AUC: [0.7500000000000002], 1 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","XGBClassifier Acc Train: [0.9895833333333334], 2 of KFold 5\n","XGBClassifier Acc Test: [0.75], 2 of KFold 5\n","XGBClassifier Recall: [0.8333333333333334], 2 of KFold 5\n","XGBClassifier Precission: [0.7142857142857143], 2 of KFold 5\n","XGBClassifier AUC: [0.7500000000000002], 2 of KFold 5\n","---------------------------\n","----------AFTER------------\n","XGBClassifier Acc Train: [0.9895833333333334, 0.9791666666666666], 2 of KFold 5\n","XGBClassifier Acc Test: [0.75, 0.875], 2 of KFold 5\n","XGBClassifier Recall: [0.8333333333333334, 0.8333333333333334], 2 of KFold 5\n","XGBClassifier Precission: [0.7142857142857143, 0.9090909090909091], 2 of KFold 5\n","XGBClassifier AUC: [0.7500000000000002, 0.875], 2 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","XGBClassifier Acc Train: [0.9895833333333334, 0.9791666666666666], 3 of KFold 5\n","XGBClassifier Acc Test: [0.75, 0.875], 3 of KFold 5\n","XGBClassifier Recall: [0.8333333333333334, 0.8333333333333334], 3 of KFold 5\n","XGBClassifier Precission: [0.7142857142857143, 0.9090909090909091], 3 of KFold 5\n","XGBClassifier AUC: [0.7500000000000002, 0.875], 3 of KFold 5\n","---------------------------\n","----------AFTER------------\n","XGBClassifier Acc Train: [0.9895833333333334, 0.9791666666666666, 1.0], 3 of KFold 5\n","XGBClassifier Acc Test: [0.75, 0.875, 0.7916666666666666], 3 of KFold 5\n","XGBClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666], 3 of KFold 5\n","XGBClassifier Precission: [0.7142857142857143, 0.9090909090909091, 0.8888888888888888], 3 of KFold 5\n","XGBClassifier AUC: [0.7500000000000002, 0.875, 0.7916666666666666], 3 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","XGBClassifier Acc Train: [0.9895833333333334, 0.9791666666666666, 1.0], 4 of KFold 5\n","XGBClassifier Acc Test: [0.75, 0.875, 0.7916666666666666], 4 of KFold 5\n","XGBClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666], 4 of KFold 5\n","XGBClassifier Precission: [0.7142857142857143, 0.9090909090909091, 0.8888888888888888], 4 of KFold 5\n","XGBClassifier AUC: [0.7500000000000002, 0.875, 0.7916666666666666], 4 of KFold 5\n","---------------------------\n","----------AFTER------------\n","XGBClassifier Acc Train: [0.9895833333333334, 0.9791666666666666, 1.0, 0.9895833333333334], 4 of KFold 5\n","XGBClassifier Acc Test: [0.75, 0.875, 0.7916666666666666, 1.0], 4 of KFold 5\n","XGBClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 1.0], 4 of KFold 5\n","XGBClassifier Precission: [0.7142857142857143, 0.9090909090909091, 0.8888888888888888, 1.0], 4 of KFold 5\n","XGBClassifier AUC: [0.7500000000000002, 0.875, 0.7916666666666666, 1.0], 4 of KFold 5\n","---------------------------\n","----------BEFORE------------\n","XGBClassifier Acc Train: [0.9895833333333334, 0.9791666666666666, 1.0, 0.9895833333333334], 5 of KFold 5\n","XGBClassifier Acc Test: [0.75, 0.875, 0.7916666666666666, 1.0], 5 of KFold 5\n","XGBClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 1.0], 5 of KFold 5\n","XGBClassifier Precission: [0.7142857142857143, 0.9090909090909091, 0.8888888888888888, 1.0], 5 of KFold 5\n","XGBClassifier AUC: [0.7500000000000002, 0.875, 0.7916666666666666, 1.0], 5 of KFold 5\n","---------------------------\n","----------AFTER------------\n","XGBClassifier Acc Train: [0.9895833333333334, 0.9791666666666666, 1.0, 0.9895833333333334, 0.96875], 5 of KFold 5\n","XGBClassifier Acc Test: [0.75, 0.875, 0.7916666666666666, 1.0, 0.7916666666666666], 5 of KFold 5\n","XGBClassifier Recall: [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 1.0, 0.6666666666666666], 5 of KFold 5\n","XGBClassifier Precission: [0.7142857142857143, 0.9090909090909091, 0.8888888888888888, 1.0, 0.8888888888888888], 5 of KFold 5\n","XGBClassifier AUC: [0.7500000000000002, 0.875, 0.7916666666666666, 1.0, 0.7916666666666666], 5 of KFold 5\n","---------------------------\n","----------FINAL------------\n","XGBClassifier Acc Train: 0.9854166666666668\n","XGBClassifier Acc Test: 0.8416666666666666\n","XGBClassifier Recall: 0.8\n","XGBClassifier Precission: 0.88023088023088\n","XGBClassifier AUC: 0.8416666666666668\n","---------------------------\n"]}],"source":["## loop for all model\n","\n","datatr = []\n","datasc = []\n","Recall =[]\n","Precision =[]\n","auc =[]\n","\n","for idx, model_type in enumerate(all_model):\n","    num = 1\n","    AccTrain = []\n","    AccTest = []\n","    RecallTemp = []\n","    PrecisionTemp = []\n","    AucTemp = []\n","    nfold = 1\n","    for train_index,test_index in kf.split(X,y): \n","\n","        print(\"----------BEFORE------------\")\n","        print(\"{} Acc Train: {}, {} of KFold {}\".format(model_name[idx], AccTrain, nfold, kf.n_splits))\n","        print(\"{} Acc Test: {}, {} of KFold {}\".format(model_name[idx], AccTest, nfold, kf.n_splits))\n","        print(\"{} Recall: {}, {} of KFold {}\".format(model_name[idx], RecallTemp, nfold, kf.n_splits))\n","        print(\"{} Precission: {}, {} of KFold {}\".format(model_name[idx], PrecisionTemp, nfold, kf.n_splits))\n","        print(\"{} AUC: {}, {} of KFold {}\".format(model_name[idx], AucTemp, nfold, kf.n_splits))\n","        print(\"---------------------------\")\n","        \n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","        \n","        #y_train = y_train.map({'No diabetes': 0, 'Diabetes': 1})\n","        #y_test = y_test.map({'No diabetes': 0, 'Diabetes': 1})\n","        \n","        model = model_type()\n","        model.fit(X_train,y_train)\n","        y_pred=model.predict(X_test)\n","        \n","        AccTrain.append(model.score(X_train , y_train))\n","        AccTest.append(model.score(X_test , y_test))\n","        RecallTemp.append(recall_score(y_test,y_pred))\n","        PrecisionTemp.append(precision_score(y_test,y_pred))\n","        AucTemp.append(roc_auc_score(y_test, y_pred))\n","        \n","        print(\"----------AFTER------------\")\n","        print(\"{} Acc Train: {}, {} of KFold {}\".format(model_name[idx], AccTrain, nfold, kf.n_splits))\n","        print(\"{} Acc Test: {}, {} of KFold {}\".format(model_name[idx], AccTest, nfold, kf.n_splits))\n","        print(\"{} Recall: {}, {} of KFold {}\".format(model_name[idx], RecallTemp, nfold, kf.n_splits))\n","        print(\"{} Precission: {}, {} of KFold {}\".format(model_name[idx], PrecisionTemp, nfold, kf.n_splits))\n","        print(\"{} AUC: {}, {} of KFold {}\".format(model_name[idx], AucTemp, nfold, kf.n_splits))\n","        print(\"---------------------------\")\n","        \n","        nfold += 1\n","    \n","    print(\"----------FINAL------------\")\n","    print(\"{} Acc Train: {}\".format(model_name[idx], np.mean(AccTrain)))\n","    print(\"{} Acc Test: {}\".format(model_name[idx], np.mean(AccTest)))\n","    print(\"{} Recall: {}\".format(model_name[idx], np.mean(RecallTemp)))\n","    print(\"{} Precission: {}\".format(model_name[idx], np.mean(PrecisionTemp)))\n","    print(\"{} AUC: {}\".format(model_name[idx], np.mean(AucTemp)))\n","    print(\"---------------------------\")\n","    datatr.append(np.mean(AccTrain))\n","    datasc.append(np.mean(AccTest))\n","    Recall.append(np.mean(RecallTemp))\n","    Precision.append(np.mean(PrecisionTemp))\n","    auc.append(np.mean(AucTemp))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy training</th>\n","      <th>Accuracy test</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>AUC</th>\n","      <th>gap</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DecisionTreeClassifier</td>\n","      <td>1.000000</td>\n","      <td>0.783333</td>\n","      <td>0.792857</td>\n","      <td>0.783333</td>\n","      <td>0.783333</td>\n","      <td>0.216667</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LogisticRegression</td>\n","      <td>0.872917</td>\n","      <td>0.858333</td>\n","      <td>0.928846</td>\n","      <td>0.783333</td>\n","      <td>0.858333</td>\n","      <td>0.014583</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>KNeighborsClassifier</td>\n","      <td>0.879167</td>\n","      <td>0.783333</td>\n","      <td>0.825794</td>\n","      <td>0.733333</td>\n","      <td>0.783333</td>\n","      <td>0.095833</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GaussianNB</td>\n","      <td>0.820833</td>\n","      <td>0.825000</td>\n","      <td>0.907093</td>\n","      <td>0.733333</td>\n","      <td>0.825000</td>\n","      <td>0.004167</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>RandomForestClassifier</td>\n","      <td>1.000000</td>\n","      <td>0.841667</td>\n","      <td>0.851329</td>\n","      <td>0.833333</td>\n","      <td>0.841667</td>\n","      <td>0.158333</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>ExtraTreesClassifier</td>\n","      <td>1.000000</td>\n","      <td>0.825000</td>\n","      <td>0.847302</td>\n","      <td>0.800000</td>\n","      <td>0.825000</td>\n","      <td>0.175000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>XGBClassifier</td>\n","      <td>0.985417</td>\n","      <td>0.841667</td>\n","      <td>0.880231</td>\n","      <td>0.800000</td>\n","      <td>0.841667</td>\n","      <td>0.143750</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    model  Accuracy training  Accuracy test  Precision  \\\n","0  DecisionTreeClassifier           1.000000       0.783333   0.792857   \n","1      LogisticRegression           0.872917       0.858333   0.928846   \n","2    KNeighborsClassifier           0.879167       0.783333   0.825794   \n","3              GaussianNB           0.820833       0.825000   0.907093   \n","4  RandomForestClassifier           1.000000       0.841667   0.851329   \n","5    ExtraTreesClassifier           1.000000       0.825000   0.847302   \n","6           XGBClassifier           0.985417       0.841667   0.880231   \n","\n","     Recall       AUC       gap  \n","0  0.783333  0.783333  0.216667  \n","1  0.783333  0.858333  0.014583  \n","2  0.733333  0.783333  0.095833  \n","3  0.733333  0.825000  0.004167  \n","4  0.833333  0.841667  0.158333  \n","5  0.800000  0.825000  0.175000  \n","6  0.800000  0.841667  0.143750  "]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["# Compare model\n","data_hasil = pd.DataFrame()\n","data_hasil['model'] = model_name\n","data_hasil['Accuracy training'] = datatr\n","data_hasil['Accuracy test'] = datasc\n","data_hasil['Precision'] = Precision\n","data_hasil['Recall']= Recall\n","data_hasil['AUC']=auc\n","data_hasil['gap'] = abs(data_hasil['Accuracy training'] - data_hasil['Accuracy test'])\n","data_hasil"]},{"cell_type":"markdown","metadata":{},"source":["Karena dalam kasus ini perlu mempertimbangkan nilai Recall yang tinggi. Maka, model yang akan digunakan adalah RandomForestClassifier"]},{"cell_type":"markdown","id":"62ba7cab-97d3-400c-8174-546121f98b32","metadata":{},"source":["## Random Forest Classifier\t\n"]},{"cell_type":"markdown","id":"01c6a48d-667a-4157-a214-dbc98d7a8b76","metadata":{},"source":["only use Glucose to classify whether a patient is diabetes positive or not.\n"]},{"cell_type":"code","execution_count":19,"id":"84c7a1d6-9fa5-4762-858c-f94baed05e1a","metadata":{},"outputs":[],"source":["X_simple = balanced[['Glucose']]\n","y = balanced['Diabetes']\n","\n","# Split the data\n","X_train_simple, X_test_simple, y_train_simple, y_test_simple = train_test_split(X_simple, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"]},{"data":{"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"â–¸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"â–¾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n","             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n","                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n","                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n","                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n","                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n","             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n","             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n","                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n","                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n","                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n","                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n","             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(min_samples_split=5, n_estimators=50, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(min_samples_split=5, n_estimators=50, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"],"text/plain":["GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n","             param_grid={'max_depth': [None, 10, 20, 30],\n","                         'max_features': ['sqrt', 'log2'],\n","                         'min_samples_leaf': [1, 2, 4],\n","                         'min_samples_split': [2, 5, 10],\n","                         'n_estimators': [50, 100, 200]},\n","             scoring='accuracy', verbose=2)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["rf = RandomForestClassifier(random_state=42)\n","param_grid = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'max_features': ['sqrt', 'log2']\n","}\n","\n","grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n","\n","# Fit model ke data\n","grid_search.fit(X_train_simple, y_train_simple)"]},{"cell_type":"markdown","metadata":{},"source":["Let's see if we can increase the accuracy with hyperparameter tuning. Hyperparameter tuning is the process of optimizing the hyperparameters of a machine learning model to improve its performance. In this case, an example of hyperparameter would be the number of neighbors. \n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Hyperparameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n","[[11  2]\n"," [ 1 10]]\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.85      0.88        13\n","           1       0.83      0.91      0.87        11\n","\n","    accuracy                           0.88        24\n","   macro avg       0.88      0.88      0.87        24\n","weighted avg       0.88      0.88      0.88        24\n","\n"]}],"source":["# Hasil hyperparameter terbaik\n","print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","# Prediksi dengan model terbaik\n","best_rf = grid_search.best_estimator_\n","y_pred_simple = best_rf.predict(X_test_simple)\n","\n","# Evaluasi performa model\n","print(confusion_matrix(y_test_simple, y_pred_simple))\n","print(classification_report(y_test_simple, y_pred_simple))\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Akurasi: 87.50%\n"]}],"source":["best_rf.fit(X_train_simple, y_train_simple)\n","\n"," # Memprediksi data uji\n","y_pred_simple = best_rf.predict(X_test_simple)\n","\n"," # Menghitung akurasi\n","accuracy = accuracy_score(y_test_simple, y_pred_simple)\n","print(f\"Akurasi: {accuracy:.2%}\")"]},{"cell_type":"markdown","id":"f8d10255-2782-4f5b-b2c3-76e16d41a2f6","metadata":{},"source":["This time, the accuracy is 87.50%, which is good considering that you are fitting on only the Glucose column instead of the all of the columns.\n"]},{"cell_type":"markdown","metadata":{},"source":["Uji coba pada data baru"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0    Diabetes\n","1    Diabetes\n","dtype: object\n"]}],"source":["X_new = pd.DataFrame({\n","    'Glucose': [120, 130]\n","    # Tambahkan fitur lain sesuai dengan yang digunakan saat pelatihan\n","})\n","\n","y_new_pred = best_rf.predict(X_new)\n","y_new_pred = pd.Series(y_new_pred).map({1: 'Diabetes', 0: 'No Diabetes'})\n","\n","# Melihat hasil prediksi\n","print(y_new_pred)"]},{"cell_type":"markdown","id":"eb494624-19e8-4dce-8012-2c9b975b608f","metadata":{},"source":["---\n"]},{"cell_type":"markdown","id":"3c8e3b67-1123-465b-95d3-4012f2474f85","metadata":{},"source":["Copyright Â© 2020 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"prev_pub_hash":"14dedef3117389ce4c6295c15ac4885e020bb27187d544806a97743b0f922b3a"},"nbformat":4,"nbformat_minor":4}
